


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchvision.datasets &mdash; Torchvision master documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/custom_torchvision.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery-rendered-html.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="torchvision.io" href="io.html" />
    <link rel="prev" title="torchvision" href="index.html" />
  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117752657-2');
    </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active docs-active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/elastic/">
                  <span class="dropdown-title">TorchElastic</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorch’s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/vision/versions.html'>master (0.11.0a0+bd3a4ab ) &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <p><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">torchvision.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="io.html">torchvision.io</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">torchvision.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="ops.html">torchvision.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="transforms.html">torchvision.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">torchvision.utils</a></li>
</ul>
<p><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="auto_examples/index.html">Example gallery</a></li>
</ul>
<p><span class="caption-text">PyTorch Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/docs">PyTorch</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/elastic/">TorchElastic</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>torchvision.datasets</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/datasets.rst.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <section id="torchvision-datasets">
<h1>torchvision.datasets<a class="headerlink" href="#torchvision-datasets" title="Permalink to this headline">¶</a></h1>
<p>All datasets are subclasses of <a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset" title="(in PyTorch v1.8.0a0+56b43f4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></a>
i.e, they have <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code> and <code class="docutils literal notranslate"><span class="pre">__len__</span></code> methods implemented.
Hence, they can all be passed to a <a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="(in PyTorch v1.8.0a0+56b43f4)"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.data.DataLoader</span></code></a>
which can load multiple samples in parallel using <code class="docutils literal notranslate"><span class="pre">torch.multiprocessing</span></code> workers.
For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">imagenet_data</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">ImageNet</span><span class="p">(</span><span class="s1">&#39;path/to/imagenet_root/&#39;</span><span class="p">)</span>
<span class="n">data_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">imagenet_data</span><span class="p">,</span>
                                          <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                          <span class="n">num_workers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">nThreads</span><span class="p">)</span>
</pre></div>
</div>
<p>All the datasets have almost similar API. They all have two common arguments:
<code class="docutils literal notranslate"><span class="pre">transform</span></code> and  <code class="docutils literal notranslate"><span class="pre">target_transform</span></code> to transform the input and target respectively.
You can also create your own datasets using the provided <a class="reference internal" href="#base-classes-datasets"><span class="std std-ref">base classes</span></a>.</p>
<section id="caltech">
<h2>Caltech<a class="headerlink" href="#caltech" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.Caltech101">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">Caltech101</code><span class="sig-paren">(</span><em class="sig-param">root: str, target_type: Union[List[str], str] = 'category', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/caltech.html#Caltech101"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Caltech101" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://www.vision.caltech.edu/Image_Datasets/Caltech101/">Caltech 101</a> Dataset.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This class needs <a class="reference external" href="https://docs.scipy.org/doc/">scipy</a> to load target files from <cite>.mat</cite> format.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of dataset where directory
<code class="docutils literal notranslate"><span class="pre">caltech101</span></code> exists or will be saved to if download is set to True.</p></li>
<li><p><strong>target_type</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a><em>, </em><em>optional</em>) – Type of target to use, <code class="docutils literal notranslate"><span class="pre">category</span></code> or</p></li>
<li><p><strong>Can also be a list to output a tuple with all specified target types.</strong> (<em>annotation.</em>) – </p></li>
<li><p><strong>represents the target class, and annotation is a list of points</strong> (<em>category</em>) – </p></li>
<li><p><strong>a hand-generated outline. Defaults to category.</strong> (<em>from</em>) – </p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchvision.datasets.Caltech101.__getitem__">
<code class="sig-name descname">__getitem__</code><span class="sig-paren">(</span><em class="sig-param">index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/caltech.html#Caltech101.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Caltech101.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(image, target) where the type of target specified by target_type.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchvision.datasets.Caltech256">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">Caltech256</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em>, <em class="sig-param">download: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/caltech.html#Caltech256"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Caltech256" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://www.vision.caltech.edu/Image_Datasets/Caltech256/">Caltech 256</a> Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of dataset where directory
<code class="docutils literal notranslate"><span class="pre">caltech256</span></code> exists or will be saved to if download is set to True.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchvision.datasets.Caltech256.__getitem__">
<code class="sig-name descname">__getitem__</code><span class="sig-paren">(</span><em class="sig-param">index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/caltech.html#Caltech256.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Caltech256.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(image, target) where target is index of the target class.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="celeba">
<h2>CelebA<a class="headerlink" href="#celeba" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.CelebA">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">CelebA</code><span class="sig-paren">(</span><em class="sig-param">root: str, split: str = 'train', target_type: Union[List[str], str] = 'attr', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, download: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/celeba.html#CelebA"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.CelebA" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html">Large-scale CelebFaces Attributes (CelebA) Dataset</a> Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory where images are downloaded to.</p></li>
<li><p><strong>split</strong> (<em>string</em>) – One of {‘train’, ‘valid’, ‘test’, ‘all’}.
Accordingly dataset is selected.</p></li>
<li><p><strong>target_type</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a><em>, </em><em>optional</em>) – <p>Type of target to use, <code class="docutils literal notranslate"><span class="pre">attr</span></code>, <code class="docutils literal notranslate"><span class="pre">identity</span></code>, <code class="docutils literal notranslate"><span class="pre">bbox</span></code>,
or <code class="docutils literal notranslate"><span class="pre">landmarks</span></code>. Can also be a list to output a tuple with all specified target types.
The targets represent:</p>
<blockquote>
<div><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">attr</span></code> (np.array shape=(40,) dtype=int): binary (0, 1) labels for attributes</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">identity</span></code> (int): label for each person (data points with the same identity are the same person)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bbox</span></code> (np.array shape=(4,) dtype=int): bounding box (x, y, width, height)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">landmarks</span></code> (np.array shape=(10,) dtype=int): landmark points (lefteye_x, lefteye_y, righteye_x,
righteye_y, nose_x, nose_y, leftmouth_x, leftmouth_y, rightmouth_x, rightmouth_y)</p></li>
</ul>
</div></blockquote>
<p>Defaults to <code class="docutils literal notranslate"><span class="pre">attr</span></code>. If empty, <code class="docutils literal notranslate"><span class="pre">None</span></code> will be returned as target.</p>
</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.ToTensor</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="cifar">
<h2>CIFAR<a class="headerlink" href="#cifar" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.CIFAR10">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">CIFAR10</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">train: bool = True</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em>, <em class="sig-param">download: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/cifar.html#CIFAR10"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.CIFAR10" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR10</a> Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of dataset where directory
<code class="docutils literal notranslate"><span class="pre">cifar-10-batches-py</span></code> exists or will be saved to if download is set to True.</p></li>
<li><p><strong>train</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, creates dataset from training set, otherwise
creates from test set.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchvision.datasets.CIFAR10.__getitem__">
<code class="sig-name descname">__getitem__</code><span class="sig-paren">(</span><em class="sig-param">index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/cifar.html#CIFAR10.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.CIFAR10.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(image, target) where target is index of the target class.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchvision.datasets.CIFAR100">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">CIFAR100</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">train: bool = True</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em>, <em class="sig-param">download: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/cifar.html#CIFAR100"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.CIFAR100" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR100</a> Dataset.</p>
<p>This is a subclass of the <cite>CIFAR10</cite> Dataset.</p>
</dd></dl>

</section>
<section id="cityscapes">
<h2>Cityscapes<a class="headerlink" href="#cityscapes" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Requires Cityscape to be downloaded.</p>
</div>
<dl class="class">
<dt id="torchvision.datasets.Cityscapes">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">Cityscapes</code><span class="sig-paren">(</span><em class="sig-param">root: str, split: str = 'train', mode: str = 'fine', target_type: Union[List[str], str] = 'instance', transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, transforms: Optional[Callable] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/cityscapes.html#Cityscapes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Cityscapes" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://www.cityscapes-dataset.com/">Cityscapes</a> Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of dataset where directory <code class="docutils literal notranslate"><span class="pre">leftImg8bit</span></code>
and <code class="docutils literal notranslate"><span class="pre">gtFine</span></code> or <code class="docutils literal notranslate"><span class="pre">gtCoarse</span></code> are located.</p></li>
<li><p><strong>split</strong> (<em>string</em><em>, </em><em>optional</em>) – The image split to use, <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">test</span></code> or <code class="docutils literal notranslate"><span class="pre">val</span></code> if mode=”fine”
otherwise <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">train_extra</span></code> or <code class="docutils literal notranslate"><span class="pre">val</span></code></p></li>
<li><p><strong>mode</strong> (<em>string</em><em>, </em><em>optional</em>) – The quality mode to use, <code class="docutils literal notranslate"><span class="pre">fine</span></code> or <code class="docutils literal notranslate"><span class="pre">coarse</span></code></p></li>
<li><p><strong>target_type</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a><em>, </em><em>optional</em>) – Type of target to use, <code class="docutils literal notranslate"><span class="pre">instance</span></code>, <code class="docutils literal notranslate"><span class="pre">semantic</span></code>, <code class="docutils literal notranslate"><span class="pre">polygon</span></code>
or <code class="docutils literal notranslate"><span class="pre">color</span></code>. Can also be a list to output a tuple with all specified target types.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in a PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>transforms</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes input sample and its target as entry
and returns a transformed version.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<p>Get semantic segmentation target</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">Cityscapes</span><span class="p">(</span><span class="s1">&#39;./data/cityscapes&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;fine&#39;</span><span class="p">,</span>
                     <span class="n">target_type</span><span class="o">=</span><span class="s1">&#39;semantic&#39;</span><span class="p">)</span>

<span class="n">img</span><span class="p">,</span> <span class="n">smnt</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>Get multiple targets</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">Cityscapes</span><span class="p">(</span><span class="s1">&#39;./data/cityscapes&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;fine&#39;</span><span class="p">,</span>
                     <span class="n">target_type</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;instance&#39;</span><span class="p">,</span> <span class="s1">&#39;color&#39;</span><span class="p">,</span> <span class="s1">&#39;polygon&#39;</span><span class="p">])</span>

<span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="n">inst</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">poly</span><span class="p">)</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>Validate on the “coarse” set</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">Cityscapes</span><span class="p">(</span><span class="s1">&#39;./data/cityscapes&#39;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s1">&#39;val&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;coarse&#39;</span><span class="p">,</span>
                     <span class="n">target_type</span><span class="o">=</span><span class="s1">&#39;semantic&#39;</span><span class="p">)</span>

<span class="n">img</span><span class="p">,</span> <span class="n">smnt</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<dl class="method">
<dt id="torchvision.datasets.Cityscapes.__getitem__">
<code class="sig-name descname">__getitem__</code><span class="sig-paren">(</span><em class="sig-param">index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/cityscapes.html#Cityscapes.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Cityscapes.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(image, target) where target is a tuple of all target types if target_type is a list with more
than one item. Otherwise target is a json object if target_type=”polygon”, else the image segmentation.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="coco">
<h2>COCO<a class="headerlink" href="#coco" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>These require the <a class="reference external" href="https://github.com/pdollar/coco/tree/master/PythonAPI">COCO API to be installed</a></p>
</div>
<section id="captions">
<h3>Captions<a class="headerlink" href="#captions" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torchvision.datasets.CocoCaptions">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">CocoCaptions</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">annFile: str</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em>, <em class="sig-param">transforms: Optional[Callable] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/coco.html#CocoCaptions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.CocoCaptions" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://cocodataset.org/#captions-2015">MS Coco Captions</a> Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory where images are downloaded to.</p></li>
<li><p><strong>annFile</strong> (<em>string</em>) – Path to json annotation file.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.ToTensor</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>transforms</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes input sample and its target as entry
and returns a transformed version.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">dset</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="n">cap</span> <span class="o">=</span> <span class="n">dset</span><span class="o">.</span><span class="n">CocoCaptions</span><span class="p">(</span><span class="n">root</span> <span class="o">=</span> <span class="s1">&#39;dir where images are&#39;</span><span class="p">,</span>
                        <span class="n">annFile</span> <span class="o">=</span> <span class="s1">&#39;json annotation file&#39;</span><span class="p">,</span>
                        <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Number of samples: &#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">cap</span><span class="p">))</span>
<span class="n">img</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">cap</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="c1"># load 4th sample</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Image Size: &quot;</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Number</span> <span class="n">of</span> <span class="n">samples</span><span class="p">:</span> <span class="mi">82783</span>
<span class="n">Image</span> <span class="n">Size</span><span class="p">:</span> <span class="p">(</span><span class="mi">3</span><span class="n">L</span><span class="p">,</span> <span class="mi">427</span><span class="n">L</span><span class="p">,</span> <span class="mi">640</span><span class="n">L</span><span class="p">)</span>
<span class="p">[</span><span class="sa">u</span><span class="s1">&#39;A plane emitting smoke stream flying over a mountain.&#39;</span><span class="p">,</span>
<span class="sa">u</span><span class="s1">&#39;A plane darts across a bright blue sky behind a mountain covered in snow&#39;</span><span class="p">,</span>
<span class="sa">u</span><span class="s1">&#39;A plane leaves a contrail above the snowy mountain top.&#39;</span><span class="p">,</span>
<span class="sa">u</span><span class="s1">&#39;A mountain that has a plane flying overheard in the distance.&#39;</span><span class="p">,</span>
<span class="sa">u</span><span class="s1">&#39;A mountain view with a plume of smoke in the background&#39;</span><span class="p">]</span>
</pre></div>
</div>
</dd></dl>

</section>
<section id="detection">
<h3>Detection<a class="headerlink" href="#detection" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torchvision.datasets.CocoDetection">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">CocoDetection</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">annFile: str</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em>, <em class="sig-param">transforms: Optional[Callable] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/coco.html#CocoDetection"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.CocoDetection" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://cocodataset.org/#detection-2016">MS Coco Detection</a> Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory where images are downloaded to.</p></li>
<li><p><strong>annFile</strong> (<em>string</em>) – Path to json annotation file.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.ToTensor</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>transforms</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes input sample and its target as entry
and returns a transformed version.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>
<section id="emnist">
<h2>EMNIST<a class="headerlink" href="#emnist" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.EMNIST">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">EMNIST</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">split: str</em>, <em class="sig-param">**kwargs: Any</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/mnist.html#EMNIST"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.EMNIST" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.westernsydney.edu.au/bens/home/reproducible_research/emnist">EMNIST</a> Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of dataset where <code class="docutils literal notranslate"><span class="pre">EMNIST/processed/training.pt</span></code>
and  <code class="docutils literal notranslate"><span class="pre">EMNIST/processed/test.pt</span></code> exist.</p></li>
<li><p><strong>split</strong> (<em>string</em>) – The dataset has 6 different splits: <code class="docutils literal notranslate"><span class="pre">byclass</span></code>, <code class="docutils literal notranslate"><span class="pre">bymerge</span></code>,
<code class="docutils literal notranslate"><span class="pre">balanced</span></code>, <code class="docutils literal notranslate"><span class="pre">letters</span></code>, <code class="docutils literal notranslate"><span class="pre">digits</span></code> and <code class="docutils literal notranslate"><span class="pre">mnist</span></code>. This argument specifies
which one to use.</p></li>
<li><p><strong>train</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, creates dataset from <code class="docutils literal notranslate"><span class="pre">training.pt</span></code>,
otherwise from <code class="docutils literal notranslate"><span class="pre">test.pt</span></code>.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="fakedata">
<h2>FakeData<a class="headerlink" href="#fakedata" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.FakeData">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">FakeData</code><span class="sig-paren">(</span><em class="sig-param">size: int = 1000</em>, <em class="sig-param">image_size: Tuple[int</em>, <em class="sig-param">int</em>, <em class="sig-param">int] = (3</em>, <em class="sig-param">224</em>, <em class="sig-param">224)</em>, <em class="sig-param">num_classes: int = 10</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em>, <em class="sig-param">random_offset: int = 0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/fakedata.html#FakeData"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.FakeData" title="Permalink to this definition">¶</a></dt>
<dd><p>A fake dataset that returns randomly generated images and returns them as PIL images</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – Size of the dataset. Default: 1000 images</p></li>
<li><p><strong>image_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a><em>, </em><em>optional</em>) – Size if the returned images. Default: (3, 224, 224)</p></li>
<li><p><strong>num_classes</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – Number of classes in the dataset. Default: 10</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>random_offset</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Offsets the index-based random seed used to
generate each image. Default: 0</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="fashion-mnist">
<h2>Fashion-MNIST<a class="headerlink" href="#fashion-mnist" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.FashionMNIST">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">FashionMNIST</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">train: bool = True</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em>, <em class="sig-param">download: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/mnist.html#FashionMNIST"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.FashionMNIST" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://github.com/zalandoresearch/fashion-mnist">Fashion-MNIST</a> Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of dataset where <code class="docutils literal notranslate"><span class="pre">FashionMNIST/processed/training.pt</span></code>
and  <code class="docutils literal notranslate"><span class="pre">FashionMNIST/processed/test.pt</span></code> exist.</p></li>
<li><p><strong>train</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, creates dataset from <code class="docutils literal notranslate"><span class="pre">training.pt</span></code>,
otherwise from <code class="docutils literal notranslate"><span class="pre">test.pt</span></code>.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="flickr">
<h2>Flickr<a class="headerlink" href="#flickr" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.Flickr8k">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">Flickr8k</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">ann_file: str</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/flickr.html#Flickr8k"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Flickr8k" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://hockenmaier.cs.illinois.edu/8k-pictures.html">Flickr8k Entities</a> Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory where images are downloaded to.</p></li>
<li><p><strong>ann_file</strong> (<em>string</em>) – Path to annotation file.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in a PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.ToTensor</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchvision.datasets.Flickr8k.__getitem__">
<code class="sig-name descname">__getitem__</code><span class="sig-paren">(</span><em class="sig-param">index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/flickr.html#Flickr8k.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Flickr8k.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple (image, target). target is a list of captions for the image.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchvision.datasets.Flickr30k">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">Flickr30k</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">ann_file: str</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/flickr.html#Flickr30k"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Flickr30k" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://web.engr.illinois.edu/~bplumme2/Flickr30kEntities/">Flickr30k Entities</a> Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory where images are downloaded to.</p></li>
<li><p><strong>ann_file</strong> (<em>string</em>) – Path to annotation file.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in a PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.ToTensor</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchvision.datasets.Flickr30k.__getitem__">
<code class="sig-name descname">__getitem__</code><span class="sig-paren">(</span><em class="sig-param">index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/flickr.html#Flickr30k.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Flickr30k.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple (image, target). target is a list of captions for the image.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="hmdb51">
<h2>HMDB51<a class="headerlink" href="#hmdb51" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.HMDB51">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">HMDB51</code><span class="sig-paren">(</span><em class="sig-param">root</em>, <em class="sig-param">annotation_path</em>, <em class="sig-param">frames_per_clip</em>, <em class="sig-param">step_between_clips=1</em>, <em class="sig-param">frame_rate=None</em>, <em class="sig-param">fold=1</em>, <em class="sig-param">train=True</em>, <em class="sig-param">transform=None</em>, <em class="sig-param">_precomputed_metadata=None</em>, <em class="sig-param">num_workers=1</em>, <em class="sig-param">_video_width=0</em>, <em class="sig-param">_video_height=0</em>, <em class="sig-param">_video_min_dimension=0</em>, <em class="sig-param">_audio_samples=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/hmdb51.html#HMDB51"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.HMDB51" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/">HMDB51</a>
dataset.</p>
<p>HMDB51 is an action recognition video dataset.
This dataset consider every video as a collection of video clips of fixed size, specified
by <code class="docutils literal notranslate"><span class="pre">frames_per_clip</span></code>, where the step in frames between each clip is given by
<code class="docutils literal notranslate"><span class="pre">step_between_clips</span></code>.</p>
<p>To give an example, for 2 videos with 10 and 15 frames respectively, if <code class="docutils literal notranslate"><span class="pre">frames_per_clip=5</span></code>
and <code class="docutils literal notranslate"><span class="pre">step_between_clips=5</span></code>, the dataset size will be (2 + 3) = 5, where the first two
elements will come from video 1, and the next three elements from video 2.
Note that we drop clips which do not have exactly <code class="docutils literal notranslate"><span class="pre">frames_per_clip</span></code> elements, so not all
frames in a video might be present.</p>
<p>Internally, it uses a VideoClips object to handle clip creation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of the HMDB51 Dataset.</p></li>
<li><p><strong>annotation_path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Path to the folder containing the split files.</p></li>
<li><p><strong>frames_per_clip</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of frames in a clip.</p></li>
<li><p><strong>step_between_clips</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of frames between each clip.</p></li>
<li><p><strong>fold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – Which fold to use. Should be between 1 and 3.</p></li>
<li><p><strong>train</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, creates a dataset from the train split,
otherwise from the <code class="docutils literal notranslate"><span class="pre">test</span></code> split.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in a TxHxWxC video
and returns a transformed version.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A 3-tuple with the following entries:</p>
<blockquote>
<div><ul class="simple">
<li><p>video (Tensor[T, H, W, C]): The <cite>T</cite> video frames</p></li>
<li><p>audio(Tensor[K, L]): the audio frames, where <cite>K</cite> is the number of channels
and <cite>L</cite> is the number of points</p></li>
<li><p>label (int): class of the video clip</p></li>
</ul>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="imagenet">
<h2>ImageNet<a class="headerlink" href="#imagenet" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.ImageNet">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">ImageNet</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">split: str = 'train'</em>, <em class="sig-param">download: Optional[str] = None</em>, <em class="sig-param">**kwargs: Any</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/imagenet.html#ImageNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.ImageNet" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://image-net.org/">ImageNet</a> 2012 Classification Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of the ImageNet Dataset.</p></li>
<li><p><strong>split</strong> (<em>string</em><em>, </em><em>optional</em>) – The dataset split, supports <code class="docutils literal notranslate"><span class="pre">train</span></code>, or <code class="docutils literal notranslate"><span class="pre">val</span></code>.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>loader</strong> – A function to load an image given its path.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This requires <cite>scipy</cite> to be installed</p>
</div>
</section>
<section id="kinetics-400">
<h2>Kinetics-400<a class="headerlink" href="#kinetics-400" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.Kinetics400">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">Kinetics400</code><span class="sig-paren">(</span><em class="sig-param">root</em>, <em class="sig-param">frames_per_clip</em>, <em class="sig-param">step_between_clips=1</em>, <em class="sig-param">frame_rate=None</em>, <em class="sig-param">extensions=('avi'</em>, <em class="sig-param">)</em>, <em class="sig-param">transform=None</em>, <em class="sig-param">_precomputed_metadata=None</em>, <em class="sig-param">num_workers=1</em>, <em class="sig-param">_video_width=0</em>, <em class="sig-param">_video_height=0</em>, <em class="sig-param">_video_min_dimension=0</em>, <em class="sig-param">_audio_samples=0</em>, <em class="sig-param">_audio_channels=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/kinetics.html#Kinetics400"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Kinetics400" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://deepmind.com/research/open-source/open-source-datasets/kinetics/">Kinetics-400</a>
dataset.</p>
<p>Kinetics-400 is an action recognition video dataset.
This dataset consider every video as a collection of video clips of fixed size, specified
by <code class="docutils literal notranslate"><span class="pre">frames_per_clip</span></code>, where the step in frames between each clip is given by
<code class="docutils literal notranslate"><span class="pre">step_between_clips</span></code>.</p>
<p>To give an example, for 2 videos with 10 and 15 frames respectively, if <code class="docutils literal notranslate"><span class="pre">frames_per_clip=5</span></code>
and <code class="docutils literal notranslate"><span class="pre">step_between_clips=5</span></code>, the dataset size will be (2 + 3) = 5, where the first two
elements will come from video 1, and the next three elements from video 2.
Note that we drop clips which do not have exactly <code class="docutils literal notranslate"><span class="pre">frames_per_clip</span></code> elements, so not all
frames in a video might be present.</p>
<p>Internally, it uses a VideoClips object to handle clip creation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – <p>Root directory of the Kinetics-400 Dataset. Should be structured as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>root/
├── class1
│   ├── clip1.avi
│   ├── clip2.avi
│   └── ...
└── class2
    ├── clipx.avi
    └── ...
</pre></div>
</div>
</p></li>
<li><p><strong>frames_per_clip</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – number of frames in a clip</p></li>
<li><p><strong>step_between_clips</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – number of frames between each clip</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in a TxHxWxC video
and returns a transformed version.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A 3-tuple with the following entries:</p>
<blockquote>
<div><ul class="simple">
<li><p>video (Tensor[T, H, W, C]): the <cite>T</cite> video frames</p></li>
<li><p>audio(Tensor[K, L]): the audio frames, where <cite>K</cite> is the number of channels
and <cite>L</cite> is the number of points</p></li>
<li><p>label (int): class of the video clip</p></li>
</ul>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="kitti">
<h2>KITTI<a class="headerlink" href="#kitti" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.Kitti">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">Kitti</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">train: bool = True</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em>, <em class="sig-param">transforms: Optional[Callable] = None</em>, <em class="sig-param">download: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/kitti.html#Kitti"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Kitti" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://www.cvlibs.net/datasets/kitti">KITTI</a> Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – <p>Root directory where images are downloaded to.
Expects the following folder structure if download=False:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&lt;root&gt;
    └── Kitti
        └─ raw
            ├── training
            |   ├── image_2
            |   └── label_2
            └── testing
                └── image_2
</pre></div>
</div>
</p></li>
<li><p><strong>train</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – Use <code class="docutils literal notranslate"><span class="pre">train</span></code> split if true, else <code class="docutils literal notranslate"><span class="pre">test</span></code> split.
Defaults to <code class="docutils literal notranslate"><span class="pre">train</span></code>.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in a PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.ToTensor</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>transforms</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes input sample
and its target as entry and returns a transformed version.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchvision.datasets.Kitti.__getitem__">
<code class="sig-name descname">__getitem__</code><span class="sig-paren">(</span><em class="sig-param">index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/kitti.html#Kitti.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Kitti.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><p>Get item at a given index.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>(image, target), where
target is a list of dictionaries with the following keys:</p>
<ul class="simple">
<li><p>type: str</p></li>
<li><p>truncated: float</p></li>
<li><p>occluded: int</p></li>
<li><p>alpha: float</p></li>
<li><p>bbox: float[4]</p></li>
<li><p>dimensions: float[3]</p></li>
<li><p>locations: float[3]</p></li>
<li><p>rotation_y: float</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="kmnist">
<h2>KMNIST<a class="headerlink" href="#kmnist" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.KMNIST">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">KMNIST</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">train: bool = True</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em>, <em class="sig-param">download: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/mnist.html#KMNIST"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.KMNIST" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://github.com/rois-codh/kmnist">Kuzushiji-MNIST</a> Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of dataset where <code class="docutils literal notranslate"><span class="pre">KMNIST/processed/training.pt</span></code>
and  <code class="docutils literal notranslate"><span class="pre">KMNIST/processed/test.pt</span></code> exist.</p></li>
<li><p><strong>train</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, creates dataset from <code class="docutils literal notranslate"><span class="pre">training.pt</span></code>,
otherwise from <code class="docutils literal notranslate"><span class="pre">test.pt</span></code>.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="lsun">
<h2>LSUN<a class="headerlink" href="#lsun" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.LSUN">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">LSUN</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">classes: Union[str</em>, <em class="sig-param">List[str]] = 'train'</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/lsun.html#LSUN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.LSUN" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.yf.io/p/lsun">LSUN</a> dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory for the database files.</p></li>
<li><p><strong>classes</strong> (<em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a>) – One of {‘train’, ‘val’, ‘test’} or a list of
categories to load. e,g. [‘bedroom_train’, ‘church_outdoor_train’].</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchvision.datasets.LSUN.__getitem__">
<code class="sig-name descname">__getitem__</code><span class="sig-paren">(</span><em class="sig-param">index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/lsun.html#LSUN.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.LSUN.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple (image, target) where target is the index of the target category.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="mnist">
<h2>MNIST<a class="headerlink" href="#mnist" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.MNIST">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">MNIST</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">train: bool = True</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em>, <em class="sig-param">download: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/mnist.html#MNIST"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.MNIST" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://yann.lecun.com/exdb/mnist/">MNIST</a> Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of dataset where <code class="docutils literal notranslate"><span class="pre">MNIST/processed/training.pt</span></code>
and  <code class="docutils literal notranslate"><span class="pre">MNIST/processed/test.pt</span></code> exist.</p></li>
<li><p><strong>train</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, creates dataset from <code class="docutils literal notranslate"><span class="pre">training.pt</span></code>,
otherwise from <code class="docutils literal notranslate"><span class="pre">test.pt</span></code>.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="omniglot">
<h2>Omniglot<a class="headerlink" href="#omniglot" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.Omniglot">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">Omniglot</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">background: bool = True</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em>, <em class="sig-param">download: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/omniglot.html#Omniglot"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Omniglot" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://github.com/brendenlake/omniglot">Omniglot</a> Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of dataset where directory
<code class="docutils literal notranslate"><span class="pre">omniglot-py</span></code> exists.</p></li>
<li><p><strong>background</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, creates dataset from the “background” set, otherwise
creates from the “evaluation” set. This terminology is defined by the authors.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset zip files from the internet and
puts it in root directory. If the zip files are already downloaded, they are not
downloaded again.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="phototour">
<h2>PhotoTour<a class="headerlink" href="#phototour" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.PhotoTour">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">PhotoTour</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">name: str</em>, <em class="sig-param">train: bool = True</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">download: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/phototour.html#PhotoTour"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.PhotoTour" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://matthewalunbrown.com/patchdata/patchdata.html">Multi-view Stereo Correspondence</a> Dataset.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We only provide the newer version of the dataset, since the authors state that it</p>
<blockquote>
<div><p>is more suitable for training descriptors based on difference of Gaussian, or Harris corners, as the
patches are centred on real interest point detections, rather than being projections of 3D points as is the
case in the old dataset.</p>
</div></blockquote>
<p>The original dataset is available under <a class="reference external" href="http://phototour.cs.washington.edu/patches/default.htm">http://phototour.cs.washington.edu/patches/default.htm</a>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory where images are.</p></li>
<li><p><strong>name</strong> (<em>string</em>) – Name of the dataset to load.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchvision.datasets.PhotoTour.__getitem__">
<code class="sig-name descname">__getitem__</code><span class="sig-paren">(</span><em class="sig-param">index: int</em><span class="sig-paren">)</span> &#x2192; Union[torch.Tensor, Tuple[Any, Any, torch.Tensor]]<a class="reference internal" href="_modules/torchvision/datasets/phototour.html#PhotoTour.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.PhotoTour.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(data1, data2, matches)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="places365">
<h2>Places365<a class="headerlink" href="#places365" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.Places365">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">Places365</code><span class="sig-paren">(</span><em class="sig-param">root: str, split: str = 'train-standard', small: bool = False, download: bool = False, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, loader: Callable[[str], Any] = &lt;function default_loader&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/places365.html#Places365"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.Places365" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://places2.csail.mit.edu/index.html">Places365</a> classification dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of the Places365 dataset.</p></li>
<li><p><strong>split</strong> (<em>string</em><em>, </em><em>optional</em>) – The dataset split. Can be one of <code class="docutils literal notranslate"><span class="pre">train-standard</span></code> (default), <code class="docutils literal notranslate"><span class="pre">train-challenge</span></code>,
<code class="docutils literal notranslate"><span class="pre">val</span></code>.</p></li>
<li><p><strong>small</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, uses the small images, i. e. resized to 256 x 256 pixels, instead of the
high resolution ones.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, downloads the dataset components and places them in <code class="docutils literal notranslate"><span class="pre">root</span></code>. Already
downloaded archives are not downloaded again.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>loader</strong> – A function to load an image given its path.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#RuntimeError" title="(in Python v3.9)"><strong>RuntimeError</strong></a> – If <code class="docutils literal notranslate"><span class="pre">download</span> <span class="pre">is</span> <span class="pre">False</span></code> and the meta files, i. e. the devkit, are not present or corrupted.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#RuntimeError" title="(in Python v3.9)"><strong>RuntimeError</strong></a> – If <code class="docutils literal notranslate"><span class="pre">download</span> <span class="pre">is</span> <span class="pre">True</span></code> and the image archive is already extracted.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="qmnist">
<h2>QMNIST<a class="headerlink" href="#qmnist" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.QMNIST">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">QMNIST</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">what: Optional[str] = None</em>, <em class="sig-param">compat: bool = True</em>, <em class="sig-param">train: bool = True</em>, <em class="sig-param">**kwargs: Any</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/mnist.html#QMNIST"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.QMNIST" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://github.com/facebookresearch/qmnist">QMNIST</a> Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of dataset whose <code class="docutils literal notranslate"><span class="pre">processed</span></code>
subdir contains torch binary files with the datasets.</p></li>
<li><p><strong>what</strong> (<em>string</em><em>,</em><em>optional</em>) – Can be ‘train’, ‘test’, ‘test10k’,
‘test50k’, or ‘nist’ for respectively the mnist compatible
training set, the 60k qmnist testing set, the 10k qmnist
examples that match the mnist testing set, the 50k
remaining qmnist testing examples, or all the nist
digits. The default is to select ‘train’ or ‘test’
according to the compatibility argument ‘train’.</p></li>
<li><p><strong>compat</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>,</em><em>optional</em>) – A boolean that says whether the target
for each example is class number (for compatibility with
the MNIST dataloader) or a torch vector containing the
full qmnist information. Default=True.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from
the internet and puts it in root directory. If dataset is
already downloaded, it is not downloaded again.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that
takes in an PIL image and returns a transformed
version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform
that takes in the target and transforms it.</p></li>
<li><p><strong>train</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>,</em><em>optional</em><em>,</em><em>compatibility</em>) – When argument ‘what’ is
not specified, this boolean decides whether to load the
training set ot the testing set.  Default: True.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="sbd">
<h2>SBD<a class="headerlink" href="#sbd" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.SBDataset">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">SBDataset</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">image_set: str = 'train'</em>, <em class="sig-param">mode: str = 'boundaries'</em>, <em class="sig-param">download: bool = False</em>, <em class="sig-param">transforms: Optional[Callable] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/sbd.html#SBDataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.SBDataset" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://home.bharathh.info/pubs/codes/SBD/download.html">Semantic Boundaries Dataset</a></p>
<p>The SBD currently contains annotations from 11355 images taken from the PASCAL VOC 2011 dataset.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please note that the train and val splits included with this dataset are different from
the splits in the PASCAL VOC dataset. In particular some “train” images might be part of
VOC2012 val.
If you are interested in testing on VOC 2012 val, then use <cite>image_set=’train_noval’</cite>,
which excludes all val images.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This class needs <a class="reference external" href="https://docs.scipy.org/doc/">scipy</a> to load target files from <cite>.mat</cite> format.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of the Semantic Boundaries Dataset</p></li>
<li><p><strong>image_set</strong> (<em>string</em><em>, </em><em>optional</em>) – Select the image_set to use, <code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">val</span></code> or <code class="docutils literal notranslate"><span class="pre">train_noval</span></code>.
Image set <code class="docutils literal notranslate"><span class="pre">train_noval</span></code> excludes VOC 2012 val images.</p></li>
<li><p><strong>mode</strong> (<em>string</em><em>, </em><em>optional</em>) – Select target type. Possible values ‘boundaries’ or ‘segmentation’.
In case of ‘boundaries’, the target is an array of shape <cite>[num_classes, H, W]</cite>,
where <cite>num_classes=20</cite>.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</p></li>
<li><p><strong>transforms</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes input sample and its target as entry
and returns a transformed version. Input sample is PIL image and target is a numpy array
if <cite>mode=’boundaries’</cite> or PIL image if <cite>mode=’segmentation’</cite>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="sbu">
<h2>SBU<a class="headerlink" href="#sbu" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.SBU">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">SBU</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em>, <em class="sig-param">download: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/sbu.html#SBU"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.SBU" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://www.cs.virginia.edu/~vicente/sbucaptions/">SBU Captioned Photo</a> Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of dataset where tarball
<code class="docutils literal notranslate"><span class="pre">SBUCaptionedPhotoDataset.tar.gz</span></code> exists.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in a PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchvision.datasets.SBU.__getitem__">
<code class="sig-name descname">__getitem__</code><span class="sig-paren">(</span><em class="sig-param">index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/sbu.html#SBU.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.SBU.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(image, target) where target is a caption for the photo.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="semeion">
<h2>SEMEION<a class="headerlink" href="#semeion" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.SEMEION">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">SEMEION</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em>, <em class="sig-param">download: bool = True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/semeion.html#SEMEION"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.SEMEION" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://archive.ics.uci.edu/ml/datasets/semeion+handwritten+digit">SEMEION</a> Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of dataset where directory
<code class="docutils literal notranslate"><span class="pre">semeion.py</span></code> exists.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchvision.datasets.SEMEION.__getitem__">
<code class="sig-name descname">__getitem__</code><span class="sig-paren">(</span><em class="sig-param">index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/semeion.html#SEMEION.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.SEMEION.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(image, target) where target is index of the target class.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="stl10">
<h2>STL10<a class="headerlink" href="#stl10" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.STL10">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">STL10</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">split: str = 'train'</em>, <em class="sig-param">folds: Optional[int] = None</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em>, <em class="sig-param">download: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/stl10.html#STL10"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.STL10" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://cs.stanford.edu/~acoates/stl10/">STL10</a> Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of dataset where directory
<code class="docutils literal notranslate"><span class="pre">stl10_binary</span></code> exists.</p></li>
<li><p><strong>split</strong> (<em>string</em>) – One of {‘train’, ‘test’, ‘unlabeled’, ‘train+unlabeled’}.
Accordingly dataset is selected.</p></li>
<li><p><strong>folds</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – One of {0-9} or None.
For training, loads one of the 10 pre-defined folds of 1k samples for the
standard evaluation procedure. If no value is passed, loads the 5k samples.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchvision.datasets.STL10.__getitem__">
<code class="sig-name descname">__getitem__</code><span class="sig-paren">(</span><em class="sig-param">index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/stl10.html#STL10.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.STL10.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(image, target) where target is index of the target class.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="svhn">
<h2>SVHN<a class="headerlink" href="#svhn" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.SVHN">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">SVHN</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">split: str = 'train'</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em>, <em class="sig-param">download: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/svhn.html#SVHN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.SVHN" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://ufldl.stanford.edu/housenumbers/">SVHN</a> Dataset.
Note: The SVHN dataset assigns the label <cite>10</cite> to the digit <cite>0</cite>. However, in this Dataset,
we assign the label <cite>0</cite> to the digit <cite>0</cite> to be compatible with PyTorch loss functions which
expect the class labels to be in the range <cite>[0, C-1]</cite></p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This class needs <a class="reference external" href="https://docs.scipy.org/doc/">scipy</a> to load data from <cite>.mat</cite> format.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of dataset where directory
<code class="docutils literal notranslate"><span class="pre">SVHN</span></code> exists.</p></li>
<li><p><strong>split</strong> (<em>string</em>) – One of {‘train’, ‘test’, ‘extra’}.
Accordingly dataset is selected. ‘extra’ is Extra training set.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchvision.datasets.SVHN.__getitem__">
<code class="sig-name descname">__getitem__</code><span class="sig-paren">(</span><em class="sig-param">index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/svhn.html#SVHN.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.SVHN.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(image, target) where target is index of the target class.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="ucf101">
<h2>UCF101<a class="headerlink" href="#ucf101" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.UCF101">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">UCF101</code><span class="sig-paren">(</span><em class="sig-param">root</em>, <em class="sig-param">annotation_path</em>, <em class="sig-param">frames_per_clip</em>, <em class="sig-param">step_between_clips=1</em>, <em class="sig-param">frame_rate=None</em>, <em class="sig-param">fold=1</em>, <em class="sig-param">train=True</em>, <em class="sig-param">transform=None</em>, <em class="sig-param">_precomputed_metadata=None</em>, <em class="sig-param">num_workers=1</em>, <em class="sig-param">_video_width=0</em>, <em class="sig-param">_video_height=0</em>, <em class="sig-param">_video_min_dimension=0</em>, <em class="sig-param">_audio_samples=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/ucf101.html#UCF101"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.UCF101" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.crcv.ucf.edu/data/UCF101.php">UCF101</a> dataset.</p>
<p>UCF101 is an action recognition video dataset.
This dataset consider every video as a collection of video clips of fixed size, specified
by <code class="docutils literal notranslate"><span class="pre">frames_per_clip</span></code>, where the step in frames between each clip is given by
<code class="docutils literal notranslate"><span class="pre">step_between_clips</span></code>.</p>
<p>To give an example, for 2 videos with 10 and 15 frames respectively, if <code class="docutils literal notranslate"><span class="pre">frames_per_clip=5</span></code>
and <code class="docutils literal notranslate"><span class="pre">step_between_clips=5</span></code>, the dataset size will be (2 + 3) = 5, where the first two
elements will come from video 1, and the next three elements from video 2.
Note that we drop clips which do not have exactly <code class="docutils literal notranslate"><span class="pre">frames_per_clip</span></code> elements, so not all
frames in a video might be present.</p>
<p>Internally, it uses a VideoClips object to handle clip creation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of the UCF101 Dataset.</p></li>
<li><p><strong>annotation_path</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – path to the folder containing the split files</p></li>
<li><p><strong>frames_per_clip</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – number of frames in a clip.</p></li>
<li><p><strong>step_between_clips</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – number of frames between each clip.</p></li>
<li><p><strong>fold</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>, </em><em>optional</em>) – which fold to use. Should be between 1 and 3.</p></li>
<li><p><strong>train</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, creates a dataset from the train split,
otherwise from the <code class="docutils literal notranslate"><span class="pre">test</span></code> split.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in a TxHxWxC video
and returns a transformed version.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>A 3-tuple with the following entries:</p>
<blockquote>
<div><ul class="simple">
<li><p>video (Tensor[T, H, W, C]): the <cite>T</cite> video frames</p></li>
<li><p>audio(Tensor[K, L]): the audio frames, where <cite>K</cite> is the number of channels
and <cite>L</cite> is the number of points</p></li>
<li><p>label (int): class of the video clip</p></li>
</ul>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</section>
<section id="usps">
<h2>USPS<a class="headerlink" href="#usps" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.USPS">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">USPS</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">train: bool = True</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em>, <em class="sig-param">download: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/usps.html#USPS"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.USPS" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html#usps">USPS</a> Dataset.
The data-format is : [label [index:value ]*256 n] * num_lines, where <code class="docutils literal notranslate"><span class="pre">label</span></code> lies in <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">10]</span></code>.
The value for each pixel lies in <code class="docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">1]</span></code>. Here we transform the <code class="docutils literal notranslate"><span class="pre">label</span></code> into <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">9]</span></code>
and make pixel values in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">255]</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of dataset to store``USPS`` data files.</p></li>
<li><p><strong>train</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If True, creates dataset from <code class="docutils literal notranslate"><span class="pre">usps.bz2</span></code>,
otherwise from <code class="docutils literal notranslate"><span class="pre">usps.t.bz2</span></code>.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchvision.datasets.USPS.__getitem__">
<code class="sig-name descname">__getitem__</code><span class="sig-paren">(</span><em class="sig-param">index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/usps.html#USPS.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.USPS.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(image, target) where target is index of the target class.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="voc">
<h2>VOC<a class="headerlink" href="#voc" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.VOCSegmentation">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">VOCSegmentation</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">year: str = '2012'</em>, <em class="sig-param">image_set: str = 'train'</em>, <em class="sig-param">download: bool = False</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em>, <em class="sig-param">transforms: Optional[Callable] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/voc.html#VOCSegmentation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.VOCSegmentation" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://host.robots.ox.ac.uk/pascal/VOC/">Pascal VOC</a> Segmentation Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of the VOC Dataset.</p></li>
<li><p><strong>year</strong> (<em>string</em><em>, </em><em>optional</em>) – The dataset year, supports years <code class="docutils literal notranslate"><span class="pre">&quot;2007&quot;</span></code> to <code class="docutils literal notranslate"><span class="pre">&quot;2012&quot;</span></code>.</p></li>
<li><p><strong>image_set</strong> (<em>string</em><em>, </em><em>optional</em>) – Select the image_set to use, <code class="docutils literal notranslate"><span class="pre">&quot;train&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;trainval&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;val&quot;</span></code>. If
<code class="docutils literal notranslate"><span class="pre">year==&quot;2007&quot;</span></code>, can also be <code class="docutils literal notranslate"><span class="pre">&quot;test&quot;</span></code>.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>transforms</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes input sample and its target as entry
and returns a transformed version.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchvision.datasets.VOCSegmentation.__getitem__">
<code class="sig-name descname">__getitem__</code><span class="sig-paren">(</span><em class="sig-param">index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/voc.html#VOCSegmentation.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.VOCSegmentation.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(image, target) where target is the image segmentation.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchvision.datasets.VOCDetection">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">VOCDetection</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">year: str = '2012'</em>, <em class="sig-param">image_set: str = 'train'</em>, <em class="sig-param">download: bool = False</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em>, <em class="sig-param">transforms: Optional[Callable] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/voc.html#VOCDetection"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.VOCDetection" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://host.robots.ox.ac.uk/pascal/VOC/">Pascal VOC</a> Detection Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory of the VOC Dataset.</p></li>
<li><p><strong>year</strong> (<em>string</em><em>, </em><em>optional</em>) – The dataset year, supports years <code class="docutils literal notranslate"><span class="pre">&quot;2007&quot;</span></code> to <code class="docutils literal notranslate"><span class="pre">&quot;2012&quot;</span></code>.</p></li>
<li><p><strong>image_set</strong> (<em>string</em><em>, </em><em>optional</em>) – Select the image_set to use, <code class="docutils literal notranslate"><span class="pre">&quot;train&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;trainval&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;val&quot;</span></code>. If
<code class="docutils literal notranslate"><span class="pre">year==&quot;2007&quot;</span></code>, can also be <code class="docutils literal notranslate"><span class="pre">&quot;test&quot;</span></code>.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.
(default: alphabetic indexing of VOC’s 20 classes).</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>required</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>transforms</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes input sample and its target as entry
and returns a transformed version.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchvision.datasets.VOCDetection.__getitem__">
<code class="sig-name descname">__getitem__</code><span class="sig-paren">(</span><em class="sig-param">index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/voc.html#VOCDetection.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.VOCDetection.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(image, target) where target is a dictionary of the XML tree.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="widerface">
<h2>WIDERFace<a class="headerlink" href="#widerface" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.WIDERFace">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">WIDERFace</code><span class="sig-paren">(</span><em class="sig-param">root: str</em>, <em class="sig-param">split: str = 'train'</em>, <em class="sig-param">transform: Optional[Callable] = None</em>, <em class="sig-param">target_transform: Optional[Callable] = None</em>, <em class="sig-param">download: bool = False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/widerface.html#WIDERFace"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.WIDERFace" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="http://shuoyang1213.me/WIDERFACE/">WIDERFace</a> Dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – <p>Root directory where images and annotations are downloaded to.
Expects the following folder structure if download=False:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&lt;root&gt;
    └── widerface
        ├── wider_face_split (&#39;wider_face_split.zip&#39; if compressed)
        ├── WIDER_train (&#39;WIDER_train.zip&#39; if compressed)
        ├── WIDER_val (&#39;WIDER_val.zip&#39; if compressed)
        └── WIDER_test (&#39;WIDER_test.zip&#39; if compressed)
</pre></div>
</div>
</p></li>
<li><p><strong>split</strong> (<em>string</em>) – The dataset split to use. One of {<code class="docutils literal notranslate"><span class="pre">train</span></code>, <code class="docutils literal notranslate"><span class="pre">val</span></code>, <code class="docutils literal notranslate"><span class="pre">test</span></code>}.
Defaults to <code class="docutils literal notranslate"><span class="pre">train</span></code>.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in a PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>download</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a><em>, </em><em>optional</em>) – If true, downloads the dataset from the internet and
puts it in root directory. If dataset is already downloaded, it is not
downloaded again.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchvision.datasets.WIDERFace.__getitem__">
<code class="sig-name descname">__getitem__</code><span class="sig-paren">(</span><em class="sig-param">index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/widerface.html#WIDERFace.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.WIDERFace.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(image, target) where target is a dict of annotations for all faces in the image.
target=None for the test split.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="base-classes-for-custom-datasets">
<span id="base-classes-datasets"></span><h2>Base classes for custom datasets<a class="headerlink" href="#base-classes-for-custom-datasets" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchvision.datasets.DatasetFolder">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">DatasetFolder</code><span class="sig-paren">(</span><em class="sig-param">root: str, loader: Callable[[str], Any], extensions: Optional[Tuple[str, ...]] = None, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, is_valid_file: Optional[Callable[[str], bool]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/folder.html#DatasetFolder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.DatasetFolder" title="Permalink to this definition">¶</a></dt>
<dd><p>A generic data loader.</p>
<p>This default directory structure can be customized by overriding the
<a class="reference internal" href="#torchvision.datasets.DatasetFolder.find_classes" title="torchvision.datasets.DatasetFolder.find_classes"><code class="xref py py-meth docutils literal notranslate"><span class="pre">find_classes()</span></code></a> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory path.</p></li>
<li><p><strong>loader</strong> (<em>callable</em>) – A function to load a sample given its path.</p></li>
<li><p><strong>extensions</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><em>tuple</em></a><em>[</em><em>string</em><em>]</em>) – A list of allowed extensions.
both extensions and is_valid_file should not be passed.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in
a sample and returns a transformed version.
E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code> for images.</p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes
in the target and transforms it.</p></li>
<li><p><strong>is_valid_file</strong> – A function that takes path of a file
and check if the file is a valid file (used to check of corrupt files)
both extensions and is_valid_file should not be passed.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchvision.datasets.DatasetFolder.__getitem__">
<code class="sig-name descname">__getitem__</code><span class="sig-paren">(</span><em class="sig-param">index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="reference internal" href="_modules/torchvision/datasets/folder.html#DatasetFolder.__getitem__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.DatasetFolder.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(sample, target) where target is class_index of the target class.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torchvision.datasets.DatasetFolder.find_classes">
<code class="sig-name descname">find_classes</code><span class="sig-paren">(</span><em class="sig-param">directory: str</em><span class="sig-paren">)</span> &#x2192; Tuple[List[str], Dict[str, int]]<a class="reference internal" href="_modules/torchvision/datasets/folder.html#DatasetFolder.find_classes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.DatasetFolder.find_classes" title="Permalink to this definition">¶</a></dt>
<dd><p>Find the class folders in a dataset structured as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>directory/
├── class_x
│   ├── xxx.ext
│   ├── xxy.ext
│   └── ...
│       └── xxz.ext
└── class_y
    ├── 123.ext
    ├── nsdf3.ext
    └── ...
    └── asd932_.ext
</pre></div>
</div>
<p>This method can be overridden to only consider
a subset of classes, or to adapt to a different dataset directory structure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>directory</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Root directory path, corresponding to <code class="docutils literal notranslate"><span class="pre">self.root</span></code></p>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#FileNotFoundError" title="(in Python v3.9)"><strong>FileNotFoundError</strong></a> – If <code class="docutils literal notranslate"><span class="pre">dir</span></code> has no class folders.</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List of all classes and dictionary mapping each class to an index.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>(Tuple[List[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)">str</a>], Dict[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)">str</a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a>]])</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torchvision.datasets.DatasetFolder.make_dataset">
<em class="property">static </em><code class="sig-name descname">make_dataset</code><span class="sig-paren">(</span><em class="sig-param">directory: str, class_to_idx: Dict[str, int], extensions: Optional[Tuple[str, ...]] = None, is_valid_file: Optional[Callable[[str], bool]] = None</em><span class="sig-paren">)</span> &#x2192; List[Tuple[str, int]]<a class="reference internal" href="_modules/torchvision/datasets/folder.html#DatasetFolder.make_dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.DatasetFolder.make_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates a list of samples of a form (path_to_sample, class).</p>
<p>This can be overridden to e.g. read files from a compressed zip file instead of from the disk.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>directory</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – root dataset directory, corresponding to <code class="docutils literal notranslate"><span class="pre">self.root</span></code>.</p></li>
<li><p><strong>class_to_idx</strong> (<em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a><em>]</em>) – Dictionary mapping class name to class index.</p></li>
<li><p><strong>extensions</strong> (<em>optional</em>) – A list of allowed extensions.
Either extensions or is_valid_file should be passed. Defaults to None.</p></li>
<li><p><strong>is_valid_file</strong> (<em>optional</em>) – A function that takes path of a file
and checks if the file is a valid file
(used to check of corrupt files) both extensions and
is_valid_file should not be passed. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><ul class="simple">
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.9)"><strong>ValueError</strong></a> – In case <code class="docutils literal notranslate"><span class="pre">class_to_idx</span></code> is empty.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.9)"><strong>ValueError</strong></a> – In case <code class="docutils literal notranslate"><span class="pre">extensions</span></code> and <code class="docutils literal notranslate"><span class="pre">is_valid_file</span></code> are None or both are not None.</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#FileNotFoundError" title="(in Python v3.9)"><strong>FileNotFoundError</strong></a> – In case no valid file was found for any class.</p></li>
</ul>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>samples of a form (path_to_sample, class)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>List[Tuple[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)">str</a>, <a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a>]]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchvision.datasets.ImageFolder">
<em class="property">class </em><code class="sig-prename descclassname">torchvision.datasets.</code><code class="sig-name descname">ImageFolder</code><span class="sig-paren">(</span><em class="sig-param">root: str, transform: Optional[Callable] = None, target_transform: Optional[Callable] = None, loader: Callable[[str], Any] = &lt;function default_loader&gt;, is_valid_file: Optional[Callable[[str], bool]] = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torchvision/datasets/folder.html#ImageFolder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torchvision.datasets.ImageFolder" title="Permalink to this definition">¶</a></dt>
<dd><p>A generic data loader where the images are arranged in this way by default:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">root</span><span class="o">/</span><span class="n">dog</span><span class="o">/</span><span class="n">xxx</span><span class="o">.</span><span class="n">png</span>
<span class="n">root</span><span class="o">/</span><span class="n">dog</span><span class="o">/</span><span class="n">xxy</span><span class="o">.</span><span class="n">png</span>
<span class="n">root</span><span class="o">/</span><span class="n">dog</span><span class="o">/</span><span class="p">[</span><span class="o">...</span><span class="p">]</span><span class="o">/</span><span class="n">xxz</span><span class="o">.</span><span class="n">png</span>

<span class="n">root</span><span class="o">/</span><span class="n">cat</span><span class="o">/</span><span class="mf">123.</span><span class="n">png</span>
<span class="n">root</span><span class="o">/</span><span class="n">cat</span><span class="o">/</span><span class="n">nsdf3</span><span class="o">.</span><span class="n">png</span>
<span class="n">root</span><span class="o">/</span><span class="n">cat</span><span class="o">/</span><span class="p">[</span><span class="o">...</span><span class="p">]</span><span class="o">/</span><span class="n">asd932_</span><span class="o">.</span><span class="n">png</span>
</pre></div>
</div>
<p>This class inherits from <a class="reference internal" href="#torchvision.datasets.DatasetFolder" title="torchvision.datasets.DatasetFolder"><code class="xref py py-class docutils literal notranslate"><span class="pre">DatasetFolder</span></code></a> so
the same methods can be overridden to customize the dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>string</em>) – Root directory path.</p></li>
<li><p><strong>transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that  takes in an PIL image
and returns a transformed version. E.g, <code class="docutils literal notranslate"><span class="pre">transforms.RandomCrop</span></code></p></li>
<li><p><strong>target_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function/transform that takes in the
target and transforms it.</p></li>
<li><p><strong>loader</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function to load an image given its path.</p></li>
<li><p><strong>is_valid_file</strong> – A function that takes path of an Image file
and check if the file is a valid file (used to check of corrupt files)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torchvision.datasets.ImageFolder.__getitem__">
<code class="sig-name descname">__getitem__</code><span class="sig-paren">(</span><em class="sig-param">index: int</em><span class="sig-paren">)</span> &#x2192; Tuple[Any, Any]<a class="headerlink" href="#torchvision.datasets.ImageFolder.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Index</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(sample, target) where target is class_index of the target class.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)">tuple</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="io.html" class="btn btn-neutral float-right" title="torchvision.io" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="torchvision" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017-present, Torch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">torchvision.datasets</a><ul>
<li><a class="reference internal" href="#caltech">Caltech</a></li>
<li><a class="reference internal" href="#celeba">CelebA</a></li>
<li><a class="reference internal" href="#cifar">CIFAR</a></li>
<li><a class="reference internal" href="#cityscapes">Cityscapes</a></li>
<li><a class="reference internal" href="#coco">COCO</a><ul>
<li><a class="reference internal" href="#captions">Captions</a></li>
<li><a class="reference internal" href="#detection">Detection</a></li>
</ul>
</li>
<li><a class="reference internal" href="#emnist">EMNIST</a></li>
<li><a class="reference internal" href="#fakedata">FakeData</a></li>
<li><a class="reference internal" href="#fashion-mnist">Fashion-MNIST</a></li>
<li><a class="reference internal" href="#flickr">Flickr</a></li>
<li><a class="reference internal" href="#hmdb51">HMDB51</a></li>
<li><a class="reference internal" href="#imagenet">ImageNet</a></li>
<li><a class="reference internal" href="#kinetics-400">Kinetics-400</a></li>
<li><a class="reference internal" href="#kitti">KITTI</a></li>
<li><a class="reference internal" href="#kmnist">KMNIST</a></li>
<li><a class="reference internal" href="#lsun">LSUN</a></li>
<li><a class="reference internal" href="#mnist">MNIST</a></li>
<li><a class="reference internal" href="#omniglot">Omniglot</a></li>
<li><a class="reference internal" href="#phototour">PhotoTour</a></li>
<li><a class="reference internal" href="#places365">Places365</a></li>
<li><a class="reference internal" href="#qmnist">QMNIST</a></li>
<li><a class="reference internal" href="#sbd">SBD</a></li>
<li><a class="reference internal" href="#sbu">SBU</a></li>
<li><a class="reference internal" href="#semeion">SEMEION</a></li>
<li><a class="reference internal" href="#stl10">STL10</a></li>
<li><a class="reference internal" href="#svhn">SVHN</a></li>
<li><a class="reference internal" href="#ucf101">UCF101</a></li>
<li><a class="reference internal" href="#usps">USPS</a></li>
<li><a class="reference internal" href="#voc">VOC</a></li>
<li><a class="reference internal" href="#widerface">WIDERFace</a></li>
<li><a class="reference internal" href="#base-classes-for-custom-datasets">Base classes for custom datasets</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/language_data.js"></script>
         <script src="_static/clipboard.min.js"></script>
         <script src="_static/copybutton.js"></script>
         <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
            <a href="https://www.youtube.com/pytorch" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/elastic/">TorchElastic</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>