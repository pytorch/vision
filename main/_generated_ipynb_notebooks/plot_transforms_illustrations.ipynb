{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Illustration of transforms\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Try on [collab](https://colab.research.google.com/github/pytorch/vision/blob/gh-pages/main/_generated_ipynb_notebooks/plot_transforms_illustrations.ipynb)\n    or `go to the end <sphx_glr_download_auto_examples_transforms_plot_transforms_illustrations.py>` to download the full example code.</p></div>\n\nThis example illustrates some of the various transforms available in `the\ntorchvision.transforms.v2 module <transforms>`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from PIL import Image\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torchvision.transforms import v2\n\nplt.rcParams[\"savefig.bbox\"] = 'tight'\n\n# if you change the seed, make sure that the randomly-applied transforms\n# properly show that the image can be both transformed and *not* transformed!\ntorch.manual_seed(0)\n\n# If you're trying to run that on collab, you can download the assets and the\n# helpers from https://github.com/pytorch/vision/tree/main/gallery/\nfrom helpers import plot\norig_img = Image.open(Path('../assets') / 'astronaut.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Geometric Transforms\nGeometric image transformation refers to the process of altering the geometric properties of an image,\nsuch as its shape, size, orientation, or position.\nIt involves applying mathematical operations to the image pixels or coordinates to achieve the desired transformation.\n\n### Pad\nThe :class:`~torchvision.transforms.Pad` transform\n(see also :func:`~torchvision.transforms.functional.pad`)\npads all image borders with some pixel values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "padded_imgs = [v2.Pad(padding=padding)(orig_img) for padding in (3, 10, 30, 50)]\nplot([orig_img] + padded_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Resize\nThe :class:`~torchvision.transforms.Resize` transform\n(see also :func:`~torchvision.transforms.functional.resize`)\nresizes an image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "resized_imgs = [v2.Resize(size=size)(orig_img) for size in (30, 50, 100, orig_img.size)]\nplot([orig_img] + resized_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CenterCrop\nThe :class:`~torchvision.transforms.CenterCrop` transform\n(see also :func:`~torchvision.transforms.functional.center_crop`)\ncrops the given image at the center.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "center_crops = [v2.CenterCrop(size=size)(orig_img) for size in (30, 50, 100, orig_img.size)]\nplot([orig_img] + center_crops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### FiveCrop\nThe :class:`~torchvision.transforms.FiveCrop` transform\n(see also :func:`~torchvision.transforms.functional.five_crop`)\ncrops the given image into four corners and the central crop.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "(top_left, top_right, bottom_left, bottom_right, center) = v2.FiveCrop(size=(100, 100))(orig_img)\nplot([orig_img] + [top_left, top_right, bottom_left, bottom_right, center])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomPerspective\nThe :class:`~torchvision.transforms.RandomPerspective` transform\n(see also :func:`~torchvision.transforms.functional.perspective`)\nperforms random perspective transform on an image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "perspective_transformer = v2.RandomPerspective(distortion_scale=0.6, p=1.0)\nperspective_imgs = [perspective_transformer(orig_img) for _ in range(4)]\nplot([orig_img] + perspective_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomRotation\nThe :class:`~torchvision.transforms.RandomRotation` transform\n(see also :func:`~torchvision.transforms.functional.rotate`)\nrotates an image with random angle.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rotater = v2.RandomRotation(degrees=(0, 180))\nrotated_imgs = [rotater(orig_img) for _ in range(4)]\nplot([orig_img] + rotated_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomAffine\nThe :class:`~torchvision.transforms.RandomAffine` transform\n(see also :func:`~torchvision.transforms.functional.affine`)\nperforms random affine transform on an image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "affine_transfomer = v2.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))\naffine_imgs = [affine_transfomer(orig_img) for _ in range(4)]\nplot([orig_img] + affine_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ElasticTransform\nThe :class:`~torchvision.transforms.ElasticTransform` transform\n(see also :func:`~torchvision.transforms.functional.elastic_transform`)\nRandomly transforms the morphology of objects in images and produces a\nsee-through-water-like effect.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "elastic_transformer = v2.ElasticTransform(alpha=250.0)\ntransformed_imgs = [elastic_transformer(orig_img) for _ in range(2)]\nplot([orig_img] + transformed_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomCrop\nThe :class:`~torchvision.transforms.RandomCrop` transform\n(see also :func:`~torchvision.transforms.functional.crop`)\ncrops an image at a random location.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cropper = v2.RandomCrop(size=(128, 128))\ncrops = [cropper(orig_img) for _ in range(4)]\nplot([orig_img] + crops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomResizedCrop\nThe :class:`~torchvision.transforms.RandomResizedCrop` transform\n(see also :func:`~torchvision.transforms.functional.resized_crop`)\ncrops an image at a random location, and then resizes the crop to a given\nsize.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "resize_cropper = v2.RandomResizedCrop(size=(32, 32))\nresized_crops = [resize_cropper(orig_img) for _ in range(4)]\nplot([orig_img] + resized_crops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Photometric Transforms\nPhotometric image transformation refers to the process of modifying the photometric properties of an image,\nsuch as its brightness, contrast, color, or tone.\nThese transformations are applied to change the visual appearance of an image\nwhile preserving its geometric structure.\n\nExcept :class:`~torchvision.transforms.Grayscale`, the following transforms are random,\nwhich means that the same transform\ninstance will produce different result each time it transforms a given image.\n\n### Grayscale\nThe :class:`~torchvision.transforms.Grayscale` transform\n(see also :func:`~torchvision.transforms.functional.to_grayscale`)\nconverts an image to grayscale\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gray_img = v2.Grayscale()(orig_img)\nplot([orig_img, gray_img], cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ColorJitter\nThe :class:`~torchvision.transforms.ColorJitter` transform\nrandomly changes the brightness, contrast, saturation, hue, and other properties of an image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "jitter = v2.ColorJitter(brightness=.5, hue=.3)\njittered_imgs = [jitter(orig_img) for _ in range(4)]\nplot([orig_img] + jittered_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GaussianBlur\nThe :class:`~torchvision.transforms.GaussianBlur` transform\n(see also :func:`~torchvision.transforms.functional.gaussian_blur`)\nperforms gaussian blur transform on an image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "blurrer = v2.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.))\nblurred_imgs = [blurrer(orig_img) for _ in range(4)]\nplot([orig_img] + blurred_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomInvert\nThe :class:`~torchvision.transforms.RandomInvert` transform\n(see also :func:`~torchvision.transforms.functional.invert`)\nrandomly inverts the colors of the given image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inverter = v2.RandomInvert()\ninvertered_imgs = [inverter(orig_img) for _ in range(4)]\nplot([orig_img] + invertered_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomPosterize\nThe :class:`~torchvision.transforms.RandomPosterize` transform\n(see also :func:`~torchvision.transforms.functional.posterize`)\nrandomly posterizes the image by reducing the number of bits\nof each color channel.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "posterizer = v2.RandomPosterize(bits=2)\nposterized_imgs = [posterizer(orig_img) for _ in range(4)]\nplot([orig_img] + posterized_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomSolarize\nThe :class:`~torchvision.transforms.RandomSolarize` transform\n(see also :func:`~torchvision.transforms.functional.solarize`)\nrandomly solarizes the image by inverting all pixel values above\nthe threshold.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "solarizer = v2.RandomSolarize(threshold=192.0)\nsolarized_imgs = [solarizer(orig_img) for _ in range(4)]\nplot([orig_img] + solarized_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomAdjustSharpness\nThe :class:`~torchvision.transforms.RandomAdjustSharpness` transform\n(see also :func:`~torchvision.transforms.functional.adjust_sharpness`)\nrandomly adjusts the sharpness of the given image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sharpness_adjuster = v2.RandomAdjustSharpness(sharpness_factor=2)\nsharpened_imgs = [sharpness_adjuster(orig_img) for _ in range(4)]\nplot([orig_img] + sharpened_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomAutocontrast\nThe :class:`~torchvision.transforms.RandomAutocontrast` transform\n(see also :func:`~torchvision.transforms.functional.autocontrast`)\nrandomly applies autocontrast to the given image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "autocontraster = v2.RandomAutocontrast()\nautocontrasted_imgs = [autocontraster(orig_img) for _ in range(4)]\nplot([orig_img] + autocontrasted_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomEqualize\nThe :class:`~torchvision.transforms.RandomEqualize` transform\n(see also :func:`~torchvision.transforms.functional.equalize`)\nrandomly equalizes the histogram of the given image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "equalizer = v2.RandomEqualize()\nequalized_imgs = [equalizer(orig_img) for _ in range(4)]\nplot([orig_img] + equalized_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Augmentation Transforms\nThe following transforms are combinations of multiple transforms,\neither geometric or photometric, or both.\n\n### AutoAugment\nThe :class:`~torchvision.transforms.AutoAugment` transform\nautomatically augments data based on a given auto-augmentation policy.\nSee :class:`~torchvision.transforms.AutoAugmentPolicy` for the available policies.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "policies = [v2.AutoAugmentPolicy.CIFAR10, v2.AutoAugmentPolicy.IMAGENET, v2.AutoAugmentPolicy.SVHN]\naugmenters = [v2.AutoAugment(policy) for policy in policies]\nimgs = [\n    [augmenter(orig_img) for _ in range(4)]\n    for augmenter in augmenters\n]\nrow_title = [str(policy).split('.')[-1] for policy in policies]\nplot([[orig_img] + row for row in imgs], row_title=row_title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandAugment\nThe :class:`~torchvision.transforms.RandAugment` is an alternate version of AutoAugment.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "augmenter = v2.RandAugment()\nimgs = [augmenter(orig_img) for _ in range(4)]\nplot([orig_img] + imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TrivialAugmentWide\nThe :class:`~torchvision.transforms.TrivialAugmentWide` is an alternate implementation of AutoAugment.\nHowever, instead of transforming an image multiple times, it transforms an image only once\nusing a random transform from a given list with a random strength number.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "augmenter = v2.TrivialAugmentWide()\nimgs = [augmenter(orig_img) for _ in range(4)]\nplot([orig_img] + imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AugMix\nThe :class:`~torchvision.transforms.AugMix` transform interpolates between augmented versions of an image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "augmenter = v2.AugMix()\nimgs = [augmenter(orig_img) for _ in range(4)]\nplot([orig_img] + imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Randomly-applied Transforms\n\nThe following transforms are randomly-applied given a probability ``p``.  That is, given ``p = 0.5``,\nthere is a 50% chance to return the original image, and a 50% chance to return the transformed image,\neven when called with the same transform instance!\n\n### RandomHorizontalFlip\nThe :class:`~torchvision.transforms.RandomHorizontalFlip` transform\n(see also :func:`~torchvision.transforms.functional.hflip`)\nperforms horizontal flip of an image, with a given probability.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hflipper = v2.RandomHorizontalFlip(p=0.5)\ntransformed_imgs = [hflipper(orig_img) for _ in range(4)]\nplot([orig_img] + transformed_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomVerticalFlip\nThe :class:`~torchvision.transforms.RandomVerticalFlip` transform\n(see also :func:`~torchvision.transforms.functional.vflip`)\nperforms vertical flip of an image, with a given probability.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vflipper = v2.RandomVerticalFlip(p=0.5)\ntransformed_imgs = [vflipper(orig_img) for _ in range(4)]\nplot([orig_img] + transformed_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomApply\nThe :class:`~torchvision.transforms.RandomApply` transform\nrandomly applies a list of transforms, with a given probability.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "applier = v2.RandomApply(transforms=[v2.RandomCrop(size=(64, 64))], p=0.5)\ntransformed_imgs = [applier(orig_img) for _ in range(4)]\nplot([orig_img] + transformed_imgs)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}