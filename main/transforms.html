


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Transforming and augmenting images &mdash; Torchvision main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/custom_torchvision.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Resize" href="generated/torchvision.transforms.Resize.html" />
    <link rel="prev" title="torchvision" href="index.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','UA-117752657-2');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active docs-active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorch’s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/vision/versions.html'>main (0.16.0a0+5884205) &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Transforming and augmenting images</a></li>
<li class="toctree-l1"><a class="reference internal" href="datapoints.html">Datapoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">Models and pre-trained weights</a></li>
<li class="toctree-l1"><a class="reference internal" href="datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">Utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="ops.html">Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="io.html">Reading/Writing images and videos</a></li>
<li class="toctree-l1"><a class="reference internal" href="feature_extraction.html">Feature extraction for model inspection</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples and training references</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="auto_examples/index.html">Example gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="training_references.html">Training references</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">PyTorch Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/docs">PyTorch</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/elastic/">TorchElastic</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Transforming and augmenting images</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/transforms.rst.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=UA-117752657-2"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <section id="transforming-and-augmenting-images">
<span id="transforms"></span><h1>Transforming and augmenting images<a class="headerlink" href="#transforming-and-augmenting-images" title="Permalink to this heading">¶</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In 0.15, we released a new set of transforms available in the
<code class="docutils literal notranslate"><span class="pre">torchvision.transforms.v2</span></code> namespace, which add support for transforming
not just images but also bounding boxes, masks, or videos. These transforms
are fully backward compatible with the current ones, and you’ll see them
documented below with a <cite>v2.</cite> prefix. To get started with those new
transforms, you can check out
<a class="reference internal" href="auto_examples/plot_transforms_v2_e2e.html#sphx-glr-auto-examples-plot-transforms-v2-e2e-py"><span class="std std-ref">Transforms v2: End-to-end object detection example</span></a>.
Note that these transforms are still BETA, and while we don’t expect major
breaking changes in the future, some APIs may still change according to user
feedback. Please submit any feedback you may have <a class="reference external" href="https://github.com/pytorch/vision/issues/6753">here</a>, and you can also check
out <a class="reference external" href="https://github.com/pytorch/vision/issues/7319">this issue</a> to learn
more about the APIs that we suspect might involve future changes.</p>
</div>
<p>Transforms are common image transformations available in the
<code class="docutils literal notranslate"><span class="pre">torchvision.transforms</span></code> module. They can be chained together using
<a class="reference internal" href="generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose" title="torchvision.transforms.Compose"><code class="xref py py-class docutils literal notranslate"><span class="pre">Compose</span></code></a>.
Most transform classes have a function equivalent: <a class="reference internal" href="#functional-transforms"><span class="std std-ref">functional
transforms</span></a> give fine-grained control over the
transformations.
This is useful if you have to build a more complex transformation pipeline
(e.g. in the case of segmentation tasks).</p>
<p>Most transformations accept both <a class="reference external" href="https://pillow.readthedocs.io">PIL</a> images
and tensor images, although some transformations are PIL-only and some are
tensor-only. The <a class="reference internal" href="#conversion-transforms"><span class="std std-ref">Conversion</span></a> may be used to convert to and from
PIL images, or for converting dtypes and ranges.</p>
<p>The transformations that accept tensor images also accept batches of tensor
images. A Tensor Image is a tensor with <code class="docutils literal notranslate"><span class="pre">(C,</span> <span class="pre">H,</span> <span class="pre">W)</span></code> shape, where <code class="docutils literal notranslate"><span class="pre">C</span></code> is a
number of channels, <code class="docutils literal notranslate"><span class="pre">H</span></code> and <code class="docutils literal notranslate"><span class="pre">W</span></code> are image height and width. A batch of
Tensor Images is a tensor of <code class="docutils literal notranslate"><span class="pre">(B,</span> <span class="pre">C,</span> <span class="pre">H,</span> <span class="pre">W)</span></code> shape, where <code class="docutils literal notranslate"><span class="pre">B</span></code> is a number
of images in the batch.</p>
<p>The expected range of the values of a tensor image is implicitly defined by
the tensor dtype. Tensor images with a float dtype are expected to have
values in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1)</span></code>. Tensor images with an integer dtype are expected to
have values in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">MAX_DTYPE]</span></code> where <code class="docutils literal notranslate"><span class="pre">MAX_DTYPE</span></code> is the largest value
that can be represented in that dtype.</p>
<p>Randomized transformations will apply the same transformation to all the
images of a given batch, but they will produce different transformations
across calls. For reproducible transformations across calls, you may use
<a class="reference internal" href="#functional-transforms"><span class="std std-ref">functional transforms</span></a>.</p>
<p>The following examples illustrate the use of the available transforms:</p>
<blockquote>
<div><ul>
<li><p><a class="reference internal" href="auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py"><span class="std std-ref">Illustration of transforms</span></a></p>
<blockquote>
<div><figure class="align-center">
<a class="reference internal image-reference" href="_images/sphx_glr_plot_transforms_001.png"><img alt="_images/sphx_glr_plot_transforms_001.png" src="_images/sphx_glr_plot_transforms_001.png" style="width: 408.85px; height: 94.9px;" /></a>
</figure>
</div></blockquote>
</li>
<li><p><a class="reference internal" href="auto_examples/plot_scripted_tensor_transforms.html#sphx-glr-auto-examples-plot-scripted-tensor-transforms-py"><span class="std std-ref">Tensor transforms and JIT</span></a></p>
<blockquote>
<div><figure class="align-center">
<a class="reference internal image-reference" href="_images/sphx_glr_plot_scripted_tensor_transforms_001.png"><img alt="_images/sphx_glr_plot_scripted_tensor_transforms_001.png" src="_images/sphx_glr_plot_scripted_tensor_transforms_001.png" style="width: 154.5px; height: 73.5px;" /></a>
</figure>
</div></blockquote>
</li>
</ul>
</div></blockquote>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Since v0.8.0 all random transformations are using torch default random generator to sample random parameters.
It is a backward compatibility breaking change and user should set the random state as following:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Previous versions</span>
<span class="c1"># import random</span>
<span class="c1"># random.seed(12)</span>

<span class="c1"># Now</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">17</span><span class="p">)</span>
</pre></div>
</div>
<p>Please, keep in mind that the same seed for torch random generator and Python random generator will not
produce the same results.</p>
</div>
<section id="transforms-scriptability">
<h2>Transforms scriptability<a class="headerlink" href="#transforms-scriptability" title="Permalink to this heading">¶</a></h2>
<p>In order to script the transformations, please use <code class="docutils literal notranslate"><span class="pre">torch.nn.Sequential</span></code> instead of <a class="reference internal" href="generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose" title="torchvision.transforms.Compose"><code class="xref py py-class docutils literal notranslate"><span class="pre">Compose</span></code></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">transforms</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">)),</span>
<span class="p">)</span>
<span class="n">scripted_transforms</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script</span><span class="p">(</span><span class="n">transforms</span><span class="p">)</span>
</pre></div>
</div>
<p>Make sure to use only scriptable transformations, i.e. that work with <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code> and does not require
<cite>lambda</cite> functions or <code class="docutils literal notranslate"><span class="pre">PIL.Image</span></code>.</p>
<p>For any custom transformations to be used with <code class="docutils literal notranslate"><span class="pre">torch.jit.script</span></code>, they should be derived from <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>.</p>
</section>
<section id="geometry">
<h2>Geometry<a class="headerlink" href="#geometry" title="Permalink to this heading">¶</a></h2>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.Resize.html#torchvision.transforms.Resize" title="torchvision.transforms.Resize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Resize</span></code></a>(size[, interpolation, max_size, ...])</p></td>
<td><p>Resize the input image to the given size.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.Resize.html#torchvision.transforms.v2.Resize" title="torchvision.transforms.v2.Resize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.Resize</span></code></a>(size[, interpolation, max_size, ...])</p></td>
<td><p>[BETA] Resize the input to the given size.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.ScaleJitter.html#torchvision.transforms.v2.ScaleJitter" title="torchvision.transforms.v2.ScaleJitter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.ScaleJitter</span></code></a>(target_size[, scale_range, ...])</p></td>
<td><p>[BETA] Perform Large Scale Jitter on the input according to <a class="reference external" href="https://arxiv.org/abs/2012.07177">&quot;Simple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentation&quot;</a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomShortestSize.html#torchvision.transforms.v2.RandomShortestSize" title="torchvision.transforms.v2.RandomShortestSize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomShortestSize</span></code></a>(min_size[, max_size, ...])</p></td>
<td><p>[BETA] Randomly resize the input.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomResize.html#torchvision.transforms.v2.RandomResize" title="torchvision.transforms.v2.RandomResize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomResize</span></code></a>(min_size, max_size[, ...])</p></td>
<td><p>[BETA] Randomly resize the input.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.RandomCrop.html#torchvision.transforms.RandomCrop" title="torchvision.transforms.RandomCrop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomCrop</span></code></a>(size[, padding, pad_if_needed, ...])</p></td>
<td><p>Crop the given image at a random location.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomCrop.html#torchvision.transforms.v2.RandomCrop" title="torchvision.transforms.v2.RandomCrop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomCrop</span></code></a>(size[, padding, ...])</p></td>
<td><p>[BETA] Crop the input at a random location.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.RandomResizedCrop.html#torchvision.transforms.RandomResizedCrop" title="torchvision.transforms.RandomResizedCrop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomResizedCrop</span></code></a>(size[, scale, ratio, ...])</p></td>
<td><p>Crop a random portion of image and resize it to a given size.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomResizedCrop.html#torchvision.transforms.v2.RandomResizedCrop" title="torchvision.transforms.v2.RandomResizedCrop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomResizedCrop</span></code></a>(size[, scale, ratio, ...])</p></td>
<td><p>[BETA] Crop a random portion of the input and resize it to a given size.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomIoUCrop.html#torchvision.transforms.v2.RandomIoUCrop" title="torchvision.transforms.v2.RandomIoUCrop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomIoUCrop</span></code></a>([min_scale, max_scale, ...])</p></td>
<td><p>[BETA] Random IoU crop transformation from <a class="reference external" href="https://arxiv.org/abs/1512.02325">&quot;SSD: Single Shot MultiBox Detector&quot;</a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.CenterCrop.html#torchvision.transforms.CenterCrop" title="torchvision.transforms.CenterCrop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CenterCrop</span></code></a>(size)</p></td>
<td><p>Crops the given image at the center.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.CenterCrop.html#torchvision.transforms.v2.CenterCrop" title="torchvision.transforms.v2.CenterCrop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.CenterCrop</span></code></a>(size)</p></td>
<td><p>[BETA] Crop the input at the center.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.FiveCrop.html#torchvision.transforms.FiveCrop" title="torchvision.transforms.FiveCrop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FiveCrop</span></code></a>(size)</p></td>
<td><p>Crop the given image into four corners and the central crop.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.FiveCrop.html#torchvision.transforms.v2.FiveCrop" title="torchvision.transforms.v2.FiveCrop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.FiveCrop</span></code></a>(size)</p></td>
<td><p>[BETA] Crop the image or video into four corners and the central crop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.TenCrop.html#torchvision.transforms.TenCrop" title="torchvision.transforms.TenCrop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TenCrop</span></code></a>(size[, vertical_flip])</p></td>
<td><p>Crop the given image into four corners and the central crop plus the flipped version of these (horizontal flipping is used by default).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.TenCrop.html#torchvision.transforms.v2.TenCrop" title="torchvision.transforms.v2.TenCrop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.TenCrop</span></code></a>(size[, vertical_flip])</p></td>
<td><p>[BETA] Crop the image or video into four corners and the central crop plus the flipped version of these (horizontal flipping is used by default).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.Pad.html#torchvision.transforms.Pad" title="torchvision.transforms.Pad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Pad</span></code></a>(padding[, fill, padding_mode])</p></td>
<td><p>Pad the given image on all sides with the given &quot;pad&quot; value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.Pad.html#torchvision.transforms.v2.Pad" title="torchvision.transforms.v2.Pad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.Pad</span></code></a>(padding[, fill, padding_mode])</p></td>
<td><p>[BETA] Pad the input on all sides with the given &quot;pad&quot; value.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomZoomOut.html#torchvision.transforms.v2.RandomZoomOut" title="torchvision.transforms.v2.RandomZoomOut"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomZoomOut</span></code></a>([fill, side_range, p])</p></td>
<td><p><p>[BETA] &quot;Zoom out&quot; transformation from <a class="reference external" href="https://arxiv.org/abs/1512.02325">&quot;SSD: Single Shot MultiBox Detector&quot;</a>.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.RandomRotation.html#torchvision.transforms.RandomRotation" title="torchvision.transforms.RandomRotation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomRotation</span></code></a>(degrees[, interpolation, ...])</p></td>
<td><p>Rotate the image by angle.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomRotation.html#torchvision.transforms.v2.RandomRotation" title="torchvision.transforms.v2.RandomRotation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomRotation</span></code></a>(degrees[, interpolation, ...])</p></td>
<td><p>[BETA] Rotate the input by angle.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.RandomAffine.html#torchvision.transforms.RandomAffine" title="torchvision.transforms.RandomAffine"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomAffine</span></code></a>(degrees[, translate, scale, ...])</p></td>
<td><p>Random affine transformation of the image keeping center invariant.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomAffine.html#torchvision.transforms.v2.RandomAffine" title="torchvision.transforms.v2.RandomAffine"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomAffine</span></code></a>(degrees[, translate, scale, ...])</p></td>
<td><p>[BETA] Random affine transformation the input keeping center invariant.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.RandomPerspective.html#torchvision.transforms.RandomPerspective" title="torchvision.transforms.RandomPerspective"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomPerspective</span></code></a>([distortion_scale, p, ...])</p></td>
<td><p>Performs a random perspective transformation of the given image with a given probability.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomPerspective.html#torchvision.transforms.v2.RandomPerspective" title="torchvision.transforms.v2.RandomPerspective"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomPerspective</span></code></a>([distortion_scale, p, ...])</p></td>
<td><p>[BETA] Perform a random perspective transformation of the input with a given probability.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.ElasticTransform.html#torchvision.transforms.ElasticTransform" title="torchvision.transforms.ElasticTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ElasticTransform</span></code></a>([alpha, sigma, ...])</p></td>
<td><p>Transform a tensor image with elastic transformations.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.ElasticTransform.html#torchvision.transforms.v2.ElasticTransform" title="torchvision.transforms.v2.ElasticTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.ElasticTransform</span></code></a>([alpha, sigma, ...])</p></td>
<td><p>[BETA] Transform the input with elastic transformations.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.RandomHorizontalFlip.html#torchvision.transforms.RandomHorizontalFlip" title="torchvision.transforms.RandomHorizontalFlip"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomHorizontalFlip</span></code></a>([p])</p></td>
<td><p>Horizontally flip the given image randomly with a given probability.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomHorizontalFlip.html#torchvision.transforms.v2.RandomHorizontalFlip" title="torchvision.transforms.v2.RandomHorizontalFlip"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomHorizontalFlip</span></code></a>([p])</p></td>
<td><p>[BETA] Horizontally flip the input with a given probability.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.RandomVerticalFlip.html#torchvision.transforms.RandomVerticalFlip" title="torchvision.transforms.RandomVerticalFlip"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomVerticalFlip</span></code></a>([p])</p></td>
<td><p>Vertically flip the given image randomly with a given probability.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomVerticalFlip.html#torchvision.transforms.v2.RandomVerticalFlip" title="torchvision.transforms.v2.RandomVerticalFlip"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomVerticalFlip</span></code></a>([p])</p></td>
<td><p>[BETA] Vertically flip the input with a given probability.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="color">
<h2>Color<a class="headerlink" href="#color" title="Permalink to this heading">¶</a></h2>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.ColorJitter.html#torchvision.transforms.ColorJitter" title="torchvision.transforms.ColorJitter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ColorJitter</span></code></a>([brightness, contrast, ...])</p></td>
<td><p>Randomly change the brightness, contrast, saturation and hue of an image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.ColorJitter.html#torchvision.transforms.v2.ColorJitter" title="torchvision.transforms.v2.ColorJitter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.ColorJitter</span></code></a>([brightness, contrast, ...])</p></td>
<td><p>[BETA] Randomly change the brightness, contrast, saturation and hue of an image or video.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomPhotometricDistort.html#torchvision.transforms.v2.RandomPhotometricDistort" title="torchvision.transforms.v2.RandomPhotometricDistort"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomPhotometricDistort</span></code></a>([brightness, ...])</p></td>
<td><p>[BETA] Randomly distorts the image or video as used in <a class="reference external" href="https://arxiv.org/abs/1512.02325">SSD: Single Shot MultiBox Detector</a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.Grayscale.html#torchvision.transforms.Grayscale" title="torchvision.transforms.Grayscale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Grayscale</span></code></a>([num_output_channels])</p></td>
<td><p>Convert image to grayscale.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.Grayscale.html#torchvision.transforms.v2.Grayscale" title="torchvision.transforms.v2.Grayscale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.Grayscale</span></code></a>([num_output_channels])</p></td>
<td><p>[BETA] Convert images or videos to grayscale.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.RandomGrayscale.html#torchvision.transforms.RandomGrayscale" title="torchvision.transforms.RandomGrayscale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomGrayscale</span></code></a>([p])</p></td>
<td><p>Randomly convert image to grayscale with a probability of p (default 0.1).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomGrayscale.html#torchvision.transforms.v2.RandomGrayscale" title="torchvision.transforms.v2.RandomGrayscale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomGrayscale</span></code></a>([p])</p></td>
<td><p>[BETA] Randomly convert image or videos to grayscale with a probability of p (default 0.1).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.GaussianBlur.html#torchvision.transforms.GaussianBlur" title="torchvision.transforms.GaussianBlur"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GaussianBlur</span></code></a>(kernel_size[, sigma])</p></td>
<td><p>Blurs image with randomly chosen Gaussian blur.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.GaussianBlur.html#torchvision.transforms.v2.GaussianBlur" title="torchvision.transforms.v2.GaussianBlur"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.GaussianBlur</span></code></a>(kernel_size[, sigma])</p></td>
<td><p>[BETA] Blurs image with randomly chosen Gaussian blur.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.RandomInvert.html#torchvision.transforms.RandomInvert" title="torchvision.transforms.RandomInvert"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomInvert</span></code></a>([p])</p></td>
<td><p>Inverts the colors of the given image randomly with a given probability.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomInvert.html#torchvision.transforms.v2.RandomInvert" title="torchvision.transforms.v2.RandomInvert"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomInvert</span></code></a>([p])</p></td>
<td><p>[BETA] Inverts the colors of the given image or video with a given probability.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.RandomPosterize.html#torchvision.transforms.RandomPosterize" title="torchvision.transforms.RandomPosterize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomPosterize</span></code></a>(bits[, p])</p></td>
<td><p>Posterize the image randomly with a given probability by reducing the number of bits for each color channel.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomPosterize.html#torchvision.transforms.v2.RandomPosterize" title="torchvision.transforms.v2.RandomPosterize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomPosterize</span></code></a>(bits[, p])</p></td>
<td><p>[BETA] Posterize the image or video with a given probability by reducing the number of bits for each color channel.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.RandomSolarize.html#torchvision.transforms.RandomSolarize" title="torchvision.transforms.RandomSolarize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomSolarize</span></code></a>(threshold[, p])</p></td>
<td><p>Solarize the image randomly with a given probability by inverting all pixel values above a threshold.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomSolarize.html#torchvision.transforms.v2.RandomSolarize" title="torchvision.transforms.v2.RandomSolarize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomSolarize</span></code></a>(threshold[, p])</p></td>
<td><p>[BETA] Solarize the image or video with a given probability by inverting all pixel values above a threshold.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.RandomAdjustSharpness.html#torchvision.transforms.RandomAdjustSharpness" title="torchvision.transforms.RandomAdjustSharpness"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomAdjustSharpness</span></code></a>(sharpness_factor[, p])</p></td>
<td><p>Adjust the sharpness of the image randomly with a given probability.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomAdjustSharpness.html#torchvision.transforms.v2.RandomAdjustSharpness" title="torchvision.transforms.v2.RandomAdjustSharpness"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomAdjustSharpness</span></code></a>(sharpness_factor[, p])</p></td>
<td><p>[BETA] Adjust the sharpness of the image or video with a given probability.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.RandomAutocontrast.html#torchvision.transforms.RandomAutocontrast" title="torchvision.transforms.RandomAutocontrast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomAutocontrast</span></code></a>([p])</p></td>
<td><p>Autocontrast the pixels of the given image randomly with a given probability.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomAutocontrast.html#torchvision.transforms.v2.RandomAutocontrast" title="torchvision.transforms.v2.RandomAutocontrast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomAutocontrast</span></code></a>([p])</p></td>
<td><p>[BETA] Autocontrast the pixels of the given image or video with a given probability.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.RandomEqualize.html#torchvision.transforms.RandomEqualize" title="torchvision.transforms.RandomEqualize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomEqualize</span></code></a>([p])</p></td>
<td><p>Equalize the histogram of the given image randomly with a given probability.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomEqualize.html#torchvision.transforms.v2.RandomEqualize" title="torchvision.transforms.v2.RandomEqualize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomEqualize</span></code></a>([p])</p></td>
<td><p>[BETA] Equalize the histogram of the given image or video with a given probability.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="composition">
<h2>Composition<a class="headerlink" href="#composition" title="Permalink to this heading">¶</a></h2>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.Compose.html#torchvision.transforms.Compose" title="torchvision.transforms.Compose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Compose</span></code></a>(transforms)</p></td>
<td><p>Composes several transforms together.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.Compose.html#torchvision.transforms.v2.Compose" title="torchvision.transforms.v2.Compose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.Compose</span></code></a>(transforms)</p></td>
<td><p>[BETA] Composes several transforms together.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.RandomApply.html#torchvision.transforms.RandomApply" title="torchvision.transforms.RandomApply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomApply</span></code></a>(transforms[, p])</p></td>
<td><p>Apply randomly a list of transformations with a given probability.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomApply.html#torchvision.transforms.v2.RandomApply" title="torchvision.transforms.v2.RandomApply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomApply</span></code></a>(transforms[, p])</p></td>
<td><p>[BETA] Apply randomly a list of transformations with a given probability.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.RandomChoice.html#torchvision.transforms.RandomChoice" title="torchvision.transforms.RandomChoice"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomChoice</span></code></a>(transforms[, p])</p></td>
<td><p>Apply single transformation randomly picked from a list.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomChoice.html#torchvision.transforms.v2.RandomChoice" title="torchvision.transforms.v2.RandomChoice"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomChoice</span></code></a>(transforms[, p])</p></td>
<td><p>[BETA] Apply single transformation randomly picked from a list.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.RandomOrder.html#torchvision.transforms.RandomOrder" title="torchvision.transforms.RandomOrder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomOrder</span></code></a>(transforms)</p></td>
<td><p>Apply a list of transformations in a random order.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomOrder.html#torchvision.transforms.v2.RandomOrder" title="torchvision.transforms.v2.RandomOrder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomOrder</span></code></a>(transforms)</p></td>
<td><p>[BETA] Apply a list of transformations in a random order.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="miscellaneous">
<h2>Miscellaneous<a class="headerlink" href="#miscellaneous" title="Permalink to this heading">¶</a></h2>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.LinearTransformation.html#torchvision.transforms.LinearTransformation" title="torchvision.transforms.LinearTransformation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LinearTransformation</span></code></a>(transformation_matrix, ...)</p></td>
<td><p>Transform a tensor image with a square transformation matrix and a mean_vector computed offline.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.LinearTransformation.html#torchvision.transforms.v2.LinearTransformation" title="torchvision.transforms.v2.LinearTransformation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.LinearTransformation</span></code></a>(...)</p></td>
<td><p>[BETA] Transform a tensor image or video with a square transformation matrix and a mean_vector computed offline.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.Normalize.html#torchvision.transforms.Normalize" title="torchvision.transforms.Normalize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Normalize</span></code></a>(mean, std[, inplace])</p></td>
<td><p>Normalize a tensor image with mean and standard deviation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.Normalize.html#torchvision.transforms.v2.Normalize" title="torchvision.transforms.v2.Normalize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.Normalize</span></code></a>(mean, std[, inplace])</p></td>
<td><p>[BETA] Normalize a tensor image or video with mean and standard deviation.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.RandomErasing.html#torchvision.transforms.RandomErasing" title="torchvision.transforms.RandomErasing"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandomErasing</span></code></a>([p, scale, ratio, value, inplace])</p></td>
<td><p>Randomly selects a rectangle region in a torch.Tensor image and erases its pixels.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandomErasing.html#torchvision.transforms.v2.RandomErasing" title="torchvision.transforms.v2.RandomErasing"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandomErasing</span></code></a>([p, scale, ratio, value, ...])</p></td>
<td><p>[BETA] Randomly select a rectangle region in the input image or video and erase its pixels.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.Lambda.html#torchvision.transforms.Lambda" title="torchvision.transforms.Lambda"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Lambda</span></code></a>(lambd)</p></td>
<td><p>Apply a user-defined lambda as a transform.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.Lambda.html#torchvision.transforms.v2.Lambda" title="torchvision.transforms.v2.Lambda"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.Lambda</span></code></a>(lambd, *types)</p></td>
<td><p>[BETA] Apply a user-defined function as a transform.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.SanitizeBoundingBox.html#torchvision.transforms.v2.SanitizeBoundingBox" title="torchvision.transforms.v2.SanitizeBoundingBox"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.SanitizeBoundingBox</span></code></a>([min_size, labels_getter])</p></td>
<td><p>[BETA] Remove degenerate/invalid bounding boxes and their corresponding labels and masks.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.ClampBoundingBox.html#torchvision.transforms.v2.ClampBoundingBox" title="torchvision.transforms.v2.ClampBoundingBox"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.ClampBoundingBox</span></code></a>()</p></td>
<td><p>[BETA] Clamp bounding boxes to their corresponding image dimensions.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.UniformTemporalSubsample.html#torchvision.transforms.v2.UniformTemporalSubsample" title="torchvision.transforms.v2.UniformTemporalSubsample"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.UniformTemporalSubsample</span></code></a>(num_samples)</p></td>
<td><p>[BETA] Uniformly subsample <code class="docutils literal notranslate"><span class="pre">num_samples</span></code> indices from the temporal dimension of the video.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="conversion">
<span id="conversion-transforms"></span><h2>Conversion<a class="headerlink" href="#conversion" title="Permalink to this heading">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Beware, some of these conversion transforms below will scale the values
while performing the conversion, while some may not do any scaling. By
scaling, we mean e.g. that a <code class="docutils literal notranslate"><span class="pre">uint8</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">float32</span></code> would map the [0,
255] range into [0, 1] (and vice-versa).</p>
</div>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.ToPILImage.html#torchvision.transforms.ToPILImage" title="torchvision.transforms.ToPILImage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ToPILImage</span></code></a>([mode])</p></td>
<td><p>Convert a tensor or an ndarray to PIL Image - this does not scale values.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.ToPILImage.html#torchvision.transforms.v2.ToPILImage" title="torchvision.transforms.v2.ToPILImage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.ToPILImage</span></code></a></p></td>
<td><p>alias of <a class="reference internal" href="generated/torchvision.transforms.v2.ToImagePIL.html#torchvision.transforms.v2.ToImagePIL" title="torchvision.transforms.v2._type_conversion.ToImagePIL"><code class="xref py py-class docutils literal notranslate"><span class="pre">ToImagePIL</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.ToImagePIL.html#torchvision.transforms.v2.ToImagePIL" title="torchvision.transforms.v2.ToImagePIL"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.ToImagePIL</span></code></a>([mode])</p></td>
<td><p>[BETA] Convert a tensor or an ndarray to PIL Image - this does not scale values.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.ToTensor.html#torchvision.transforms.ToTensor" title="torchvision.transforms.ToTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ToTensor</span></code></a>()</p></td>
<td><p>Convert a PIL Image or ndarray to tensor and scale the values accordingly.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.ToTensor.html#torchvision.transforms.v2.ToTensor" title="torchvision.transforms.v2.ToTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.ToTensor</span></code></a>()</p></td>
<td><p>[BETA] Convert a PIL Image or ndarray to tensor and scale the values accordingly.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.PILToTensor.html#torchvision.transforms.PILToTensor" title="torchvision.transforms.PILToTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PILToTensor</span></code></a>()</p></td>
<td><p>Convert a PIL Image to a tensor of the same type - this does not scale values.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.PILToTensor.html#torchvision.transforms.v2.PILToTensor" title="torchvision.transforms.v2.PILToTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.PILToTensor</span></code></a>()</p></td>
<td><p>[BETA] Convert a PIL Image to a tensor of the same type - this does not scale values.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.ToImageTensor.html#torchvision.transforms.v2.ToImageTensor" title="torchvision.transforms.v2.ToImageTensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.ToImageTensor</span></code></a>()</p></td>
<td><p>[BETA] Convert a tensor, ndarray, or PIL Image to <a class="reference internal" href="generated/torchvision.datapoints.Image.html#torchvision.datapoints.Image" title="torchvision.datapoints.Image"><code class="xref py py-class docutils literal notranslate"><span class="pre">Image</span></code></a> ; this does not scale values.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.ConvertImageDtype.html#torchvision.transforms.ConvertImageDtype" title="torchvision.transforms.ConvertImageDtype"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ConvertImageDtype</span></code></a>(dtype)</p></td>
<td><p>Convert a tensor image to the given <code class="docutils literal notranslate"><span class="pre">dtype</span></code> and scale the values accordingly.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.ConvertDtype.html#torchvision.transforms.v2.ConvertDtype" title="torchvision.transforms.v2.ConvertDtype"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.ConvertDtype</span></code></a>([dtype])</p></td>
<td><p>[BETA] Convert input image or video to the given <code class="docutils literal notranslate"><span class="pre">dtype</span></code> and scale the values accordingly.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.ConvertImageDtype.html#torchvision.transforms.v2.ConvertImageDtype" title="torchvision.transforms.v2.ConvertImageDtype"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.ConvertImageDtype</span></code></a></p></td>
<td><p>alias of <a class="reference internal" href="generated/torchvision.transforms.v2.ConvertDtype.html#torchvision.transforms.v2.ConvertDtype" title="torchvision.transforms.v2._meta.ConvertDtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConvertDtype</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.ToDtype.html#torchvision.transforms.v2.ToDtype" title="torchvision.transforms.v2.ToDtype"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.ToDtype</span></code></a>(dtype)</p></td>
<td><p>[BETA] Converts the input to a specific dtype - this does not scale values.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.ConvertBoundingBoxFormat.html#torchvision.transforms.v2.ConvertBoundingBoxFormat" title="torchvision.transforms.v2.ConvertBoundingBoxFormat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.ConvertBoundingBoxFormat</span></code></a>(format)</p></td>
<td><p>[BETA] Convert bounding box coordinates to the given <code class="docutils literal notranslate"><span class="pre">format</span></code>, eg from &quot;CXCYWH&quot; to &quot;XYXY&quot;.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="auto-augmentation">
<h2>Auto-Augmentation<a class="headerlink" href="#auto-augmentation" title="Permalink to this heading">¶</a></h2>
<p><a class="reference external" href="https://arxiv.org/pdf/1805.09501.pdf">AutoAugment</a> is a common Data Augmentation technique that can improve the accuracy of Image Classification models.
Though the data augmentation policies are directly linked to their trained dataset, empirical studies show that
ImageNet policies provide significant improvements when applied to other datasets.
In TorchVision we implemented 3 policies learned on the following datasets: ImageNet, CIFAR10 and SVHN.
The new transform can be used standalone or mixed-and-matched with existing transforms:</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.AutoAugmentPolicy.html#torchvision.transforms.AutoAugmentPolicy" title="torchvision.transforms.AutoAugmentPolicy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AutoAugmentPolicy</span></code></a>(value)</p></td>
<td><p>AutoAugment policies learned on different datasets.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.AutoAugment.html#torchvision.transforms.AutoAugment" title="torchvision.transforms.AutoAugment"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AutoAugment</span></code></a>([policy, interpolation, fill])</p></td>
<td><p>AutoAugment data augmentation method based on <a class="reference external" href="https://arxiv.org/pdf/1805.09501.pdf">&quot;AutoAugment: Learning Augmentation Strategies from Data&quot;</a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.AutoAugment.html#torchvision.transforms.v2.AutoAugment" title="torchvision.transforms.v2.AutoAugment"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.AutoAugment</span></code></a>([policy, interpolation, fill])</p></td>
<td><p><p>[BETA] AutoAugment data augmentation method based on <a class="reference external" href="https://arxiv.org/pdf/1805.09501.pdf">&quot;AutoAugment: Learning Augmentation Strategies from Data&quot;</a>.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.RandAugment.html#torchvision.transforms.RandAugment" title="torchvision.transforms.RandAugment"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RandAugment</span></code></a>([num_ops, magnitude, ...])</p></td>
<td><p>RandAugment data augmentation method based on <a class="reference external" href="https://arxiv.org/abs/1909.13719">&quot;RandAugment: Practical automated data augmentation with a reduced search space&quot;</a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.RandAugment.html#torchvision.transforms.v2.RandAugment" title="torchvision.transforms.v2.RandAugment"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.RandAugment</span></code></a>([num_ops, magnitude, ...])</p></td>
<td><p><p>[BETA] RandAugment data augmentation method based on <a class="reference external" href="https://arxiv.org/abs/1909.13719">&quot;RandAugment: Practical automated data augmentation with a reduced search space&quot;</a>.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.TrivialAugmentWide.html#torchvision.transforms.TrivialAugmentWide" title="torchvision.transforms.TrivialAugmentWide"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TrivialAugmentWide</span></code></a>([num_magnitude_bins, ...])</p></td>
<td><p>Dataset-independent data-augmentation with TrivialAugment Wide, as described in <a class="reference external" href="https://arxiv.org/abs/2103.10158">&quot;TrivialAugment: Tuning-free Yet State-of-the-Art Data Augmentation&quot;</a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.TrivialAugmentWide.html#torchvision.transforms.v2.TrivialAugmentWide" title="torchvision.transforms.v2.TrivialAugmentWide"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.TrivialAugmentWide</span></code></a>([num_magnitude_bins, ...])</p></td>
<td><p><p>[BETA] Dataset-independent data-augmentation with TrivialAugment Wide, as described in <a class="reference external" href="https://arxiv.org/abs/2103.10158">&quot;TrivialAugment: Tuning-free Yet State-of-the-Art Data Augmentation&quot;</a>.</p>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.AugMix.html#torchvision.transforms.AugMix" title="torchvision.transforms.AugMix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AugMix</span></code></a>([severity, mixture_width, ...])</p></td>
<td><p>AugMix data augmentation method based on <a class="reference external" href="https://arxiv.org/abs/1912.02781">&quot;AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty&quot;</a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.v2.AugMix.html#torchvision.transforms.v2.AugMix" title="torchvision.transforms.v2.AugMix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">v2.AugMix</span></code></a>([severity, mixture_width, ...])</p></td>
<td><p><p>[BETA] AugMix data augmentation method based on <a class="reference external" href="https://arxiv.org/abs/1912.02781">&quot;AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty&quot;</a>.</p>
</p></td>
</tr>
</tbody>
</table>
</section>
<section id="functional-transforms">
<span id="id7"></span><h2>Functional Transforms<a class="headerlink" href="#functional-transforms" title="Permalink to this heading">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You’ll find below the documentation for the existing
<code class="docutils literal notranslate"><span class="pre">torchvision.transforms.functional</span></code> namespace. The
<code class="docutils literal notranslate"><span class="pre">torchvision.transforms.v2.functional</span></code> namespace exists as well and can be
used! The same functionals are present, so you simply need to change your
import to rely on the <code class="docutils literal notranslate"><span class="pre">v2</span></code> namespace.</p>
</div>
<p>Functional transforms give you fine-grained control of the transformation pipeline.
As opposed to the transformations above, functional transforms don’t contain a random number
generator for their parameters.
That means you have to specify/generate all parameters, but the functional transform will give you
reproducible results across calls.</p>
<p>Example:
you can apply a functional transform with the same parameters to multiple images like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torchvision.transforms.functional</span> <span class="k">as</span> <span class="nn">TF</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="k">def</span> <span class="nf">my_segmentation_transforms</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">segmentation</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="n">angle</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="o">-</span><span class="mi">30</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">rotate</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">angle</span><span class="p">)</span>
        <span class="n">segmentation</span> <span class="o">=</span> <span class="n">TF</span><span class="o">.</span><span class="n">rotate</span><span class="p">(</span><span class="n">segmentation</span><span class="p">,</span> <span class="n">angle</span><span class="p">)</span>
    <span class="c1"># more transforms ...</span>
    <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">segmentation</span>
</pre></div>
</div>
<p>Example:
you can use a functional transform to build transform classes with custom behavior:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torchvision.transforms.functional</span> <span class="k">as</span> <span class="nn">TF</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="k">class</span> <span class="nc">MyRotationTransform</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Rotate by one of the given angles.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">angles</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">angles</span> <span class="o">=</span> <span class="n">angles</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">angle</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">angles</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">TF</span><span class="o">.</span><span class="n">rotate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">angle</span><span class="p">)</span>

<span class="n">rotation_transform</span> <span class="o">=</span> <span class="n">MyRotationTransform</span><span class="p">(</span><span class="n">angles</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">30</span><span class="p">,</span> <span class="o">-</span><span class="mi">15</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">30</span><span class="p">])</span>
</pre></div>
</div>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.adjust_brightness.html#torchvision.transforms.functional.adjust_brightness" title="torchvision.transforms.functional.adjust_brightness"><code class="xref py py-obj docutils literal notranslate"><span class="pre">adjust_brightness</span></code></a>(img, brightness_factor)</p></td>
<td><p>Adjust brightness of an image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.adjust_contrast.html#torchvision.transforms.functional.adjust_contrast" title="torchvision.transforms.functional.adjust_contrast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">adjust_contrast</span></code></a>(img, contrast_factor)</p></td>
<td><p>Adjust contrast of an image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.adjust_gamma.html#torchvision.transforms.functional.adjust_gamma" title="torchvision.transforms.functional.adjust_gamma"><code class="xref py py-obj docutils literal notranslate"><span class="pre">adjust_gamma</span></code></a>(img, gamma[, gain])</p></td>
<td><p>Perform gamma correction on an image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.adjust_hue.html#torchvision.transforms.functional.adjust_hue" title="torchvision.transforms.functional.adjust_hue"><code class="xref py py-obj docutils literal notranslate"><span class="pre">adjust_hue</span></code></a>(img, hue_factor)</p></td>
<td><p>Adjust hue of an image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.adjust_saturation.html#torchvision.transforms.functional.adjust_saturation" title="torchvision.transforms.functional.adjust_saturation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">adjust_saturation</span></code></a>(img, saturation_factor)</p></td>
<td><p>Adjust color saturation of an image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.adjust_sharpness.html#torchvision.transforms.functional.adjust_sharpness" title="torchvision.transforms.functional.adjust_sharpness"><code class="xref py py-obj docutils literal notranslate"><span class="pre">adjust_sharpness</span></code></a>(img, sharpness_factor)</p></td>
<td><p>Adjust the sharpness of an image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.affine.html#torchvision.transforms.functional.affine" title="torchvision.transforms.functional.affine"><code class="xref py py-obj docutils literal notranslate"><span class="pre">affine</span></code></a>(img, angle, translate, scale, shear)</p></td>
<td><p>Apply affine transformation on the image keeping image center invariant.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.autocontrast.html#torchvision.transforms.functional.autocontrast" title="torchvision.transforms.functional.autocontrast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">autocontrast</span></code></a>(img)</p></td>
<td><p>Maximize contrast of an image by remapping its pixels per channel so that the lowest becomes black and the lightest becomes white.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.center_crop.html#torchvision.transforms.functional.center_crop" title="torchvision.transforms.functional.center_crop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">center_crop</span></code></a>(img, output_size)</p></td>
<td><p>Crops the given image at the center.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.convert_image_dtype.html#torchvision.transforms.functional.convert_image_dtype" title="torchvision.transforms.functional.convert_image_dtype"><code class="xref py py-obj docutils literal notranslate"><span class="pre">convert_image_dtype</span></code></a>(image[, dtype])</p></td>
<td><p>Convert a tensor image to the given <code class="docutils literal notranslate"><span class="pre">dtype</span></code> and scale the values accordingly This function does not support PIL Image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.crop.html#torchvision.transforms.functional.crop" title="torchvision.transforms.functional.crop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">crop</span></code></a>(img, top, left, height, width)</p></td>
<td><p>Crop the given image at specified location and output size.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.equalize.html#torchvision.transforms.functional.equalize" title="torchvision.transforms.functional.equalize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">equalize</span></code></a>(img)</p></td>
<td><p>Equalize the histogram of an image by applying a non-linear mapping to the input in order to create a uniform distribution of grayscale values in the output.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.erase.html#torchvision.transforms.functional.erase" title="torchvision.transforms.functional.erase"><code class="xref py py-obj docutils literal notranslate"><span class="pre">erase</span></code></a>(img, i, j, h, w, v[, inplace])</p></td>
<td><p>Erase the input Tensor Image with given value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.five_crop.html#torchvision.transforms.functional.five_crop" title="torchvision.transforms.functional.five_crop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">five_crop</span></code></a>(img, size)</p></td>
<td><p>Crop the given image into four corners and the central crop.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.gaussian_blur.html#torchvision.transforms.functional.gaussian_blur" title="torchvision.transforms.functional.gaussian_blur"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gaussian_blur</span></code></a>(img, kernel_size[, sigma])</p></td>
<td><p>Performs Gaussian blurring on the image by given kernel.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.get_dimensions.html#torchvision.transforms.functional.get_dimensions" title="torchvision.transforms.functional.get_dimensions"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_dimensions</span></code></a>(img)</p></td>
<td><p>Returns the dimensions of an image as [channels, height, width].</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.get_image_num_channels.html#torchvision.transforms.functional.get_image_num_channels" title="torchvision.transforms.functional.get_image_num_channels"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_image_num_channels</span></code></a>(img)</p></td>
<td><p>Returns the number of channels of an image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.get_image_size.html#torchvision.transforms.functional.get_image_size" title="torchvision.transforms.functional.get_image_size"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_image_size</span></code></a>(img)</p></td>
<td><p>Returns the size of an image as [width, height].</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.hflip.html#torchvision.transforms.functional.hflip" title="torchvision.transforms.functional.hflip"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hflip</span></code></a>(img)</p></td>
<td><p>Horizontally flip the given image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.invert.html#torchvision.transforms.functional.invert" title="torchvision.transforms.functional.invert"><code class="xref py py-obj docutils literal notranslate"><span class="pre">invert</span></code></a>(img)</p></td>
<td><p>Invert the colors of an RGB/grayscale image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.normalize.html#torchvision.transforms.functional.normalize" title="torchvision.transforms.functional.normalize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">normalize</span></code></a>(tensor, mean, std[, inplace])</p></td>
<td><p>Normalize a float tensor image with mean and standard deviation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.pad.html#torchvision.transforms.functional.pad" title="torchvision.transforms.functional.pad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pad</span></code></a>(img, padding[, fill, padding_mode])</p></td>
<td><p>Pad the given image on all sides with the given &quot;pad&quot; value.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.perspective.html#torchvision.transforms.functional.perspective" title="torchvision.transforms.functional.perspective"><code class="xref py py-obj docutils literal notranslate"><span class="pre">perspective</span></code></a>(img, startpoints, endpoints[, ...])</p></td>
<td><p>Perform perspective transform of the given image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.pil_to_tensor.html#torchvision.transforms.functional.pil_to_tensor" title="torchvision.transforms.functional.pil_to_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pil_to_tensor</span></code></a>(pic)</p></td>
<td><p>Convert a <code class="docutils literal notranslate"><span class="pre">PIL</span> <span class="pre">Image</span></code> to a tensor of the same type.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.posterize.html#torchvision.transforms.functional.posterize" title="torchvision.transforms.functional.posterize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">posterize</span></code></a>(img, bits)</p></td>
<td><p>Posterize an image by reducing the number of bits for each color channel.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.resize.html#torchvision.transforms.functional.resize" title="torchvision.transforms.functional.resize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resize</span></code></a>(img, size[, interpolation, max_size, ...])</p></td>
<td><p>Resize the input image to the given size.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.resized_crop.html#torchvision.transforms.functional.resized_crop" title="torchvision.transforms.functional.resized_crop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resized_crop</span></code></a>(img, top, left, height, width, size)</p></td>
<td><p>Crop the given image and resize it to desired size.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.rgb_to_grayscale.html#torchvision.transforms.functional.rgb_to_grayscale" title="torchvision.transforms.functional.rgb_to_grayscale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rgb_to_grayscale</span></code></a>(img[, num_output_channels])</p></td>
<td><p>Convert RGB image to grayscale version of image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.rotate.html#torchvision.transforms.functional.rotate" title="torchvision.transforms.functional.rotate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rotate</span></code></a>(img, angle[, interpolation, expand, ...])</p></td>
<td><p>Rotate the image by angle.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.solarize.html#torchvision.transforms.functional.solarize" title="torchvision.transforms.functional.solarize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">solarize</span></code></a>(img, threshold)</p></td>
<td><p>Solarize an RGB/grayscale image by inverting all pixel values above a threshold.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.ten_crop.html#torchvision.transforms.functional.ten_crop" title="torchvision.transforms.functional.ten_crop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ten_crop</span></code></a>(img, size[, vertical_flip])</p></td>
<td><p>Generate ten cropped images from the given image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.to_grayscale.html#torchvision.transforms.functional.to_grayscale" title="torchvision.transforms.functional.to_grayscale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_grayscale</span></code></a>(img[, num_output_channels])</p></td>
<td><p>Convert PIL image of any mode (RGB, HSV, LAB, etc) to grayscale version of image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.to_pil_image.html#torchvision.transforms.functional.to_pil_image" title="torchvision.transforms.functional.to_pil_image"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_pil_image</span></code></a>(pic[, mode])</p></td>
<td><p>Convert a tensor or an ndarray to PIL Image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.to_tensor.html#torchvision.transforms.functional.to_tensor" title="torchvision.transforms.functional.to_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">to_tensor</span></code></a>(pic)</p></td>
<td><p>Convert a <code class="docutils literal notranslate"><span class="pre">PIL</span> <span class="pre">Image</span></code> or <code class="docutils literal notranslate"><span class="pre">numpy.ndarray</span></code> to tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torchvision.transforms.functional.vflip.html#torchvision.transforms.functional.vflip" title="torchvision.transforms.functional.vflip"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vflip</span></code></a>(img)</p></td>
<td><p>Vertically flip the given image.</p></td>
</tr>
</tbody>
</table>
</section>
</section>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="generated/torchvision.transforms.Resize.html" class="btn btn-neutral float-right" title="Resize" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="torchvision" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017-present, Torch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Transforming and augmenting images</a><ul>
<li><a class="reference internal" href="#transforms-scriptability">Transforms scriptability</a></li>
<li><a class="reference internal" href="#geometry">Geometry</a></li>
<li><a class="reference internal" href="#color">Color</a></li>
<li><a class="reference internal" href="#composition">Composition</a></li>
<li><a class="reference internal" href="#miscellaneous">Miscellaneous</a></li>
<li><a class="reference internal" href="#conversion">Conversion</a></li>
<li><a class="reference internal" href="#auto-augmentation">Auto-Augmentation</a></li>
<li><a class="reference internal" href="#functional-transforms">Functional Transforms</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/clipboard.min.js"></script>
         <script src="_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>
            
          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>
            
           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>