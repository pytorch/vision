


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Video API &mdash; Torchvision main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom_torchvision.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Visualization utilities" href="plot_visualization_utils.html" />
  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117752657-2');
    </script>
  
  <!-- End Google Analytics -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active docs-active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/elastic/">
                  <span class="dropdown-title">TorchElastic</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorch’s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/vision/versions.html'>main (0.11.0a0+f2a867e ) &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../datasets.html">torchvision.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../io.html">torchvision.io</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models.html">torchvision.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../feature_extraction.html">torchvision.models.feature_extraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ops.html">torchvision.ops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../transforms.html">torchvision.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils.html">torchvision.utils</a></li>
</ul>
<p class="caption"><span class="caption-text">Examples</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Example gallery</a></li>
</ul>
<p class="caption"><span class="caption-text">PyTorch Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/docs">PyTorch</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/elastic/">TorchElastic</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="index.html">Example gallery</a> &gt;</li>
        
      <li>Video API</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/auto_examples/plot_video_api.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-plot-video-api-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="video-api">
<span id="sphx-glr-auto-examples-plot-video-api-py"></span><h1>Video API<a class="headerlink" href="#video-api" title="Permalink to this headline">¶</a></h1>
<p>This example illustrates some of the APIs that torchvision offers for
videos, together with the examples on how to build datasets and more.</p>
<div class="section" id="introduction-building-a-new-video-object-and-examining-the-properties">
<h2>1. Introduction: building a new video object and examining the properties<a class="headerlink" href="#introduction-building-a-new-video-object-and-examining-the-properties" title="Permalink to this headline">¶</a></h2>
<p>First we select a video to test the object out. For the sake of argument
we’re using one from kinetics400 dataset.
To create it, we need to define the path and the stream we want to use.</p>
<p>Chosen video statistics:</p>
<ul class="simple">
<li><dl class="simple">
<dt>WUzgd7C1pWA.mp4</dt><dd><ul>
<li><dl class="simple">
<dt>source:</dt><dd><ul>
<li><p>kinetics-400</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>video:</dt><dd><ul>
<li><p>H-264</p></li>
<li><p>MPEG-4 AVC (part 10) (avc1)</p></li>
<li><p>fps: 29.97</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>audio:</dt><dd><ul>
<li><p>MPEG AAC audio (mp4a)</p></li>
<li><p>sample rate: 48K Hz</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torchvision.datasets.utils</span> <span class="kn">import</span> <span class="n">download_url</span>

<span class="c1"># Download the sample video</span>
<span class="n">download_url</span><span class="p">(</span>
    <span class="s2">&quot;https://github.com/pytorch/vision/blob/main/test/assets/videos/WUzgd7C1pWA.mp4?raw=true&quot;</span><span class="p">,</span>
    <span class="s2">&quot;.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;WUzgd7C1pWA.mp4&quot;</span>
<span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">video_path</span></a> <span class="o">=</span> <span class="s2">&quot;./WUzgd7C1pWA.mp4&quot;</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading https://raw.githubusercontent.com/pytorch/vision/main/test/assets/videos/WUzgd7C1pWA.mp4 to ./WUzgd7C1pWA.mp4

0.1%
0.2%
0.3%
0.5%
0.6%
0.7%
0.8%
0.9%
1.0%
1.2%
1.3%
1.4%
1.5%
1.6%
1.7%
1.8%
2.0%
2.1%
2.2%
2.3%
2.4%
2.5%
2.6%
2.8%
2.9%
3.0%
3.1%
3.2%
3.3%
3.5%
3.6%
3.7%
3.8%
3.9%
4.0%
4.1%
4.3%
4.4%
4.5%
4.6%
4.7%
4.8%
4.9%
5.1%
5.2%
5.3%
5.4%
5.5%
5.6%
5.8%
5.9%
6.0%
6.1%
6.2%
6.3%
6.4%
6.6%
6.7%
6.8%
6.9%
7.0%
7.1%
7.3%
7.4%
7.5%
7.6%
7.7%
7.8%
7.9%
8.1%
8.2%
8.3%
8.4%
8.5%
8.6%
8.7%
8.9%
9.0%
9.1%
9.2%
9.3%
9.4%
9.6%
9.7%
9.8%
9.9%
10.0%
10.1%
10.2%
10.4%
10.5%
10.6%
10.7%
10.8%
10.9%
11.1%
11.2%
11.3%
11.4%
11.5%
11.6%
11.7%
11.9%
12.0%
12.1%
12.2%
12.3%
12.4%
12.5%
12.7%
12.8%
12.9%
13.0%
13.1%
13.2%
13.4%
13.5%
13.6%
13.7%
13.8%
13.9%
14.0%
14.2%
14.3%
14.4%
14.5%
14.6%
14.7%
14.8%
15.0%
15.1%
15.2%
15.3%
15.4%
15.5%
15.7%
15.8%
15.9%
16.0%
16.1%
16.2%
16.3%
16.5%
16.6%
16.7%
16.8%
16.9%
17.0%
17.2%
17.3%
17.4%
17.5%
17.6%
17.7%
17.8%
18.0%
18.1%
18.2%
18.3%
18.4%
18.5%
18.6%
18.8%
18.9%
19.0%
19.1%
19.2%
19.3%
19.5%
19.6%
19.7%
19.8%
19.9%
20.0%
20.1%
20.3%
20.4%
20.5%
20.6%
20.7%
20.8%
20.9%
21.1%
21.2%
21.3%
21.4%
21.5%
21.6%
21.8%
21.9%
22.0%
22.1%
22.2%
22.3%
22.4%
22.6%
22.7%
22.8%
22.9%
23.0%
23.1%
23.3%
23.4%
23.5%
23.6%
23.7%
23.8%
23.9%
24.1%
24.2%
24.3%
24.4%
24.5%
24.6%
24.7%
24.9%
25.0%
25.1%
25.2%
25.3%
25.4%
25.6%
25.7%
25.8%
25.9%
26.0%
26.1%
26.2%
26.4%
26.5%
26.6%
26.7%
26.8%
26.9%
27.0%
27.2%
27.3%
27.4%
27.5%
27.6%
27.7%
27.9%
28.0%
28.1%
28.2%
28.3%
28.4%
28.5%
28.7%
28.8%
28.9%
29.0%
29.1%
29.2%
29.4%
29.5%
29.6%
29.7%
29.8%
29.9%
30.0%
30.2%
30.3%
30.4%
30.5%
30.6%
30.7%
30.8%
31.0%
31.1%
31.2%
31.3%
31.4%
31.5%
31.7%
31.8%
31.9%
32.0%
32.1%
32.2%
32.3%
32.5%
32.6%
32.7%
32.8%
32.9%
33.0%
33.2%
33.3%
33.4%
33.5%
33.6%
33.7%
33.8%
34.0%
34.1%
34.2%
34.3%
34.4%
34.5%
34.6%
34.8%
34.9%
35.0%
35.1%
35.2%
35.3%
35.5%
35.6%
35.7%
35.8%
35.9%
36.0%
36.1%
36.3%
36.4%
36.5%
36.6%
36.7%
36.8%
36.9%
37.1%
37.2%
37.3%
37.4%
37.5%
37.6%
37.8%
37.9%
38.0%
38.1%
38.2%
38.3%
38.4%
38.6%
38.7%
38.8%
38.9%
39.0%
39.1%
39.3%
39.4%
39.5%
39.6%
39.7%
39.8%
39.9%
40.1%
40.2%
40.3%
40.4%
40.5%
40.6%
40.7%
40.9%
41.0%
41.1%
41.2%
41.3%
41.4%
41.6%
41.7%
41.8%
41.9%
42.0%
42.1%
42.2%
42.4%
42.5%
42.6%
42.7%
42.8%
42.9%
43.0%
43.2%
43.3%
43.4%
43.5%
43.6%
43.7%
43.9%
44.0%
44.1%
44.2%
44.3%
44.4%
44.5%
44.7%
44.8%
44.9%
45.0%
45.1%
45.2%
45.4%
45.5%
45.6%
45.7%
45.8%
45.9%
46.0%
46.2%
46.3%
46.4%
46.5%
46.6%
46.7%
46.8%
47.0%
47.1%
47.2%
47.3%
47.4%
47.5%
47.7%
47.8%
47.9%
48.0%
48.1%
48.2%
48.3%
48.5%
48.6%
48.7%
48.8%
48.9%
49.0%
49.2%
49.3%
49.4%
49.5%
49.6%
49.7%
49.8%
50.0%
50.1%
50.2%
50.3%
50.4%
50.5%
50.6%
50.8%
50.9%
51.0%
51.1%
51.2%
51.3%
51.5%
51.6%
51.7%
51.8%
51.9%
52.0%
52.1%
52.3%
52.4%
52.5%
52.6%
52.7%
52.8%
52.9%
53.1%
53.2%
53.3%
53.4%
53.5%
53.6%
53.8%
53.9%
54.0%
54.1%
54.2%
54.3%
54.4%
54.6%
54.7%
54.8%
54.9%
55.0%
55.1%
55.3%
55.4%
55.5%
55.6%
55.7%
55.8%
55.9%
56.1%
56.2%
56.3%
56.4%
56.5%
56.6%
56.7%
56.9%
57.0%
57.1%
57.2%
57.3%
57.4%
57.6%
57.7%
57.8%
57.9%
58.0%
58.1%
58.2%
58.4%
58.5%
58.6%
58.7%
58.8%
58.9%
59.0%
59.2%
59.3%
59.4%
59.5%
59.6%
59.7%
59.9%
60.0%
60.1%
60.2%
60.3%
60.4%
60.5%
60.7%
60.8%
60.9%
61.0%
61.1%
61.2%
61.4%
61.5%
61.6%
61.7%
61.8%
61.9%
62.0%
62.2%
62.3%
62.4%
62.5%
62.6%
62.7%
62.8%
63.0%
63.1%
63.2%
63.3%
63.4%
63.5%
63.7%
63.8%
63.9%
64.0%
64.1%
64.2%
64.3%
64.5%
64.6%
64.7%
64.8%
64.9%
65.0%
65.1%
65.3%
65.4%
65.5%
65.6%
65.7%
65.8%
66.0%
66.1%
66.2%
66.3%
66.4%
66.5%
66.6%
66.8%
66.9%
67.0%
67.1%
67.2%
67.3%
67.5%
67.6%
67.7%
67.8%
67.9%
68.0%
68.1%
68.3%
68.4%
68.5%
68.6%
68.7%
68.8%
68.9%
69.1%
69.2%
69.3%
69.4%
69.5%
69.6%
69.8%
69.9%
70.0%
70.1%
70.2%
70.3%
70.4%
70.6%
70.7%
70.8%
70.9%
71.0%
71.1%
71.3%
71.4%
71.5%
71.6%
71.7%
71.8%
71.9%
72.1%
72.2%
72.3%
72.4%
72.5%
72.6%
72.7%
72.9%
73.0%
73.1%
73.2%
73.3%
73.4%
73.6%
73.7%
73.8%
73.9%
74.0%
74.1%
74.2%
74.4%
74.5%
74.6%
74.7%
74.8%
74.9%
75.0%
75.2%
75.3%
75.4%
75.5%
75.6%
75.7%
75.9%
76.0%
76.1%
76.2%
76.3%
76.4%
76.5%
76.7%
76.8%
76.9%
77.0%
77.1%
77.2%
77.4%
77.5%
77.6%
77.7%
77.8%
77.9%
78.0%
78.2%
78.3%
78.4%
78.5%
78.6%
78.7%
78.8%
79.0%
79.1%
79.2%
79.3%
79.4%
79.5%
79.7%
79.8%
79.9%
80.0%
80.1%
80.2%
80.3%
80.5%
80.6%
80.7%
80.8%
80.9%
81.0%
81.1%
81.3%
81.4%
81.5%
81.6%
81.7%
81.8%
82.0%
82.1%
82.2%
82.3%
82.4%
82.5%
82.6%
82.8%
82.9%
83.0%
83.1%
83.2%
83.3%
83.5%
83.6%
83.7%
83.8%
83.9%
84.0%
84.1%
84.3%
84.4%
84.5%
84.6%
84.7%
84.8%
84.9%
85.1%
85.2%
85.3%
85.4%
85.5%
85.6%
85.8%
85.9%
86.0%
86.1%
86.2%
86.3%
86.4%
86.6%
86.7%
86.8%
86.9%
87.0%
87.1%
87.2%
87.4%
87.5%
87.6%
87.7%
87.8%
87.9%
88.1%
88.2%
88.3%
88.4%
88.5%
88.6%
88.7%
88.9%
89.0%
89.1%
89.2%
89.3%
89.4%
89.6%
89.7%
89.8%
89.9%
90.0%
90.1%
90.2%
90.4%
90.5%
90.6%
90.7%
90.8%
90.9%
91.0%
91.2%
91.3%
91.4%
91.5%
91.6%
91.7%
91.9%
92.0%
92.1%
92.2%
92.3%
92.4%
92.5%
92.7%
92.8%
92.9%
93.0%
93.1%
93.2%
93.4%
93.5%
93.6%
93.7%
93.8%
93.9%
94.0%
94.2%
94.3%
94.4%
94.5%
94.6%
94.7%
94.8%
95.0%
95.1%
95.2%
95.3%
95.4%
95.5%
95.7%
95.8%
95.9%
96.0%
96.1%
96.2%
96.3%
96.5%
96.6%
96.7%
96.8%
96.9%
97.0%
97.1%
97.3%
97.4%
97.5%
97.6%
97.7%
97.8%
98.0%
98.1%
98.2%
98.3%
98.4%
98.5%
98.6%
98.8%
98.9%
99.0%
99.1%
99.2%
99.3%
99.5%
99.6%
99.7%
99.8%
99.9%
100.0%
</pre></div>
</div>
<p>Streams are defined in a similar fashion as torch devices. We encode them as strings in a form
of <code class="docutils literal notranslate"><span class="pre">stream_type:stream_id</span></code> where <code class="docutils literal notranslate"><span class="pre">stream_type</span></code> is a string and <code class="docutils literal notranslate"><span class="pre">stream_id</span></code> a long int.
The constructor accepts passing a <code class="docutils literal notranslate"><span class="pre">stream_type</span></code> only, in which case the stream is auto-discovered.
Firstly, let’s get the metadata for our particular video:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">stream</span></a> <span class="o">=</span> <span class="s2">&quot;video&quot;</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">VideoReader</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">video_path</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">stream</span></a><span class="p">)</span>
<span class="n">video</span><span class="o">.</span><span class="n">get_metadata</span><span class="p">()</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>{&#39;video&#39;: {&#39;duration&#39;: [10.9109], &#39;fps&#39;: [29.97002997002997]}, &#39;audio&#39;: {&#39;duration&#39;: [10.9], &#39;framerate&#39;: [48000.0]}, &#39;subtitles&#39;: {&#39;duration&#39;: []}, &#39;cc&#39;: {&#39;duration&#39;: []}}
</pre></div>
</div>
<p>Here we can see that video has two streams - a video and an audio stream.
Currently available stream types include [‘video’, ‘audio’].
Each descriptor consists of two parts: stream type (e.g. ‘video’) and a unique stream id
(which are determined by video encoding).
In this way, if the video container contains multiple streams of the same type,
users can access the one they want.
If only stream type is passed, the decoder auto-detects first stream of that type and returns it.</p>
<p>Let’s read all the frames from the video stream. By default, the return value of
<code class="docutils literal notranslate"><span class="pre">next(video_reader)</span></code> is a dict containing the following fields.</p>
<p>The return fields are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">data</span></code>: containing a torch.tensor</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pts</span></code>: containing a float timestamp of this particular frame</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">metadata</span></a> <span class="o">=</span> <span class="n">video</span><span class="o">.</span><span class="n">get_metadata</span><span class="p">()</span>
<span class="n">video</span><span class="o">.</span><span class="n">set_current_stream</span><span class="p">(</span><span class="s2">&quot;audio&quot;</span><span class="p">)</span>

<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frames</span></a> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># we are going to save the frames here.</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ptss</span></a> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># pts is a presentation timestamp in seconds (float) of each frame</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frame</span></a> <span class="ow">in</span> <span class="n">video</span><span class="p">:</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frames</span></a><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frame</span></a><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">])</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ptss</span></a><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frame</span></a><span class="p">[</span><span class="s1">&#39;pts&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;PTS for first five frames &quot;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">ptss</span></a><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total number of frames: &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frames</span></a><span class="p">))</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">approx_nf</span></a> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">metadata</span></a><span class="p">[</span><span class="s1">&#39;audio&#39;</span><span class="p">][</span><span class="s1">&#39;duration&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">metadata</span></a><span class="p">[</span><span class="s1">&#39;audio&#39;</span><span class="p">][</span><span class="s1">&#39;framerate&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Approx total number of datapoints we can expect: &quot;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">approx_nf</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Read data size: &quot;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frames</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frames</span></a><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>PTS for first five frames  [0.0, 0.021332999999999998, 0.042667, 0.064, 0.08533299999999999]
Total number of frames:  511
Approx total number of datapoints we can expect:  523200.0
Read data size:  523264
</pre></div>
</div>
<p>But what if we only want to read certain time segment of the video?
That can be done easily using the combination of our <code class="docutils literal notranslate"><span class="pre">seek</span></code> function, and the fact that each call
to next returns the presentation timestamp of the returned frame in seconds.</p>
<p>Given that our implementation relies on python iterators,
we can leverage itertools to simplify the process and make it more pythonic.</p>
<p>For example, if we wanted to read ten frames from second second:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">itertools</span>
<span class="n">video</span><span class="o">.</span><span class="n">set_current_stream</span><span class="p">(</span><span class="s2">&quot;video&quot;</span><span class="p">)</span>

<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frames</span></a> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># we are going to save the frames here.</span>

<span class="c1"># We seek into a second second of the video and use islice to get 10 frames since</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frame</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pts</span></a> <span class="ow">in</span> <a href="https://docs.python.org/3/library/itertools.html#itertools.islice" title="itertools.islice" class="sphx-glr-backref-module-itertools sphx-glr-backref-type-py-function"><span class="n">itertools</span><span class="o">.</span><span class="n">islice</span></a><span class="p">(</span><span class="n">video</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="mi">10</span><span class="p">):</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frames</span></a><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frame</span></a><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total number of frames: &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frames</span></a><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Total number of frames:  10
</pre></div>
</div>
<p>Or if we wanted to read from 2nd to 5th second,
We seek into a second second of the video,
then we utilize the itertools takewhile to get the
correct number of frames:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">video</span><span class="o">.</span><span class="n">set_current_stream</span><span class="p">(</span><span class="s2">&quot;video&quot;</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frames</span></a> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># we are going to save the frames here.</span>
<span class="n">video</span> <span class="o">=</span> <span class="n">video</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="k">for</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frame</span></a> <span class="ow">in</span> <a href="https://docs.python.org/3/library/itertools.html#itertools.takewhile" title="itertools.takewhile" class="sphx-glr-backref-module-itertools sphx-glr-backref-type-py-function"><span class="n">itertools</span><span class="o">.</span><span class="n">takewhile</span></a><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;pts&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">video</span><span class="p">):</span>
    <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frames</span></a><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frame</span></a><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total number of frames: &quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frames</span></a><span class="p">))</span>
<a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">approx_nf</span></a> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">video</span><span class="o">.</span><span class="n">get_metadata</span><span class="p">()[</span><span class="s1">&#39;video&#39;</span><span class="p">][</span><span class="s1">&#39;fps&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;We can expect approx: &quot;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#float" title="builtins.float" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">approx_nf</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tensor size: &quot;</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frames</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Total number of frames:  90
We can expect approx:  89.91008991008991
Tensor size:  torch.Size([3, 256, 340])
</pre></div>
</div>
</div>
<div class="section" id="building-a-sample-read-video-function">
<h2>2. Building a sample read_video function<a class="headerlink" href="#building-a-sample-read-video-function" title="Permalink to this headline">¶</a></h2>
<p>We can utilize the methods above to build the read video function that follows
the same API to the existing <code class="docutils literal notranslate"><span class="pre">read_video</span></code> function.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">example_read_video</span><span class="p">(</span><span class="n">video_object</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">read_video</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">read_audio</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">end</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">end</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">end</span> <span class="o">&lt;</span> <span class="n">start</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;end time should be larger than start time, got &quot;</span>
            <span class="s2">&quot;start time=</span><span class="si">{}</span><span class="s2"> and end time=</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="n">video_frames</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.empty.html#torch.empty" title="torch.empty" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">empty</span></a><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">video_pts</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">read_video</span><span class="p">:</span>
        <span class="n">video_object</span><span class="o">.</span><span class="n">set_current_stream</span><span class="p">(</span><span class="s2">&quot;video&quot;</span><span class="p">)</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frames</span></a> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frame</span></a> <span class="ow">in</span> <a href="https://docs.python.org/3/library/itertools.html#itertools.takewhile" title="itertools.takewhile" class="sphx-glr-backref-module-itertools sphx-glr-backref-type-py-function"><span class="n">itertools</span><span class="o">.</span><span class="n">takewhile</span></a><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;pts&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">end</span><span class="p">,</span> <span class="n">video_object</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="n">start</span><span class="p">)):</span>
            <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frames</span></a><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frame</span></a><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">])</span>
            <span class="n">video_pts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frame</span></a><span class="p">[</span><span class="s1">&#39;pts&#39;</span><span class="p">])</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frames</span></a><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">video_frames</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.stack.html#torch.stack" title="torch.stack" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">stack</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frames</span></a><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="n">audio_frames</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.empty.html#torch.empty" title="torch.empty" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">empty</span></a><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">audio_pts</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">read_audio</span><span class="p">:</span>
        <span class="n">video_object</span><span class="o">.</span><span class="n">set_current_stream</span><span class="p">(</span><span class="s2">&quot;audio&quot;</span><span class="p">)</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frames</span></a> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frame</span></a> <span class="ow">in</span> <a href="https://docs.python.org/3/library/itertools.html#itertools.takewhile" title="itertools.takewhile" class="sphx-glr-backref-module-itertools sphx-glr-backref-type-py-function"><span class="n">itertools</span><span class="o">.</span><span class="n">takewhile</span></a><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;pts&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">end</span><span class="p">,</span> <span class="n">video_object</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="n">start</span><span class="p">)):</span>
            <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frames</span></a><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frame</span></a><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">])</span>
            <span class="n">video_pts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frame</span></a><span class="p">[</span><span class="s1">&#39;pts&#39;</span><span class="p">])</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frames</span></a><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">audio_frames</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat" title="torch.cat" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cat</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frames</span></a><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">video_frames</span><span class="p">,</span> <span class="n">audio_frames</span><span class="p">,</span> <span class="p">(</span><span class="n">video_pts</span><span class="p">,</span> <span class="n">audio_pts</span><span class="p">),</span> <span class="n">video_object</span><span class="o">.</span><span class="n">get_metadata</span><span class="p">()</span>


<span class="c1"># Total number of frames should be 327 for video and 523264 datapoints for audio</span>
<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">vf</span></a><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">af</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">info</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">meta</span></a> <span class="o">=</span> <span class="n">example_read_video</span><span class="p">(</span><span class="n">video</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">vf</span></a><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">af</span></a><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>torch.Size([327, 3, 256, 340]) torch.Size([523264, 1])
</pre></div>
</div>
</div>
<div class="section" id="building-an-example-randomly-sampled-dataset-can-be-applied-to-training-dataest-of-kinetics400">
<h2>3. Building an example randomly sampled dataset (can be applied to training dataest of kinetics400)<a class="headerlink" href="#building-an-example-randomly-sampled-dataset-can-be-applied-to-training-dataest-of-kinetics400" title="Permalink to this headline">¶</a></h2>
<p>Cool, so now we can use the same principle to make the sample dataset.
We suggest trying out iterable dataset for this purpose.
Here, we are going to build an example dataset that reads randomly selected 10 frames of video.</p>
<p>Make sample dataset</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<a href="https://docs.python.org/3/library/os.html#os.makedirs" title="os.makedirs" class="sphx-glr-backref-module-os sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">makedirs</span></a><span class="p">(</span><span class="s2">&quot;./dataset&quot;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/os.html#os.makedirs" title="os.makedirs" class="sphx-glr-backref-module-os sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">makedirs</span></a><span class="p">(</span><span class="s2">&quot;./dataset/1&quot;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/os.html#os.makedirs" title="os.makedirs" class="sphx-glr-backref-module-os sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">makedirs</span></a><span class="p">(</span><span class="s2">&quot;./dataset/2&quot;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>Download the videos</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchvision.datasets.utils</span> <span class="kn">import</span> <span class="n">download_url</span>
<span class="n">download_url</span><span class="p">(</span>
    <span class="s2">&quot;https://github.com/pytorch/vision/blob/main/test/assets/videos/WUzgd7C1pWA.mp4?raw=true&quot;</span><span class="p">,</span>
    <span class="s2">&quot;./dataset/1&quot;</span><span class="p">,</span> <span class="s2">&quot;WUzgd7C1pWA.mp4&quot;</span>
<span class="p">)</span>
<span class="n">download_url</span><span class="p">(</span>
    <span class="s2">&quot;https://github.com/pytorch/vision/blob/main/test/assets/videos/RATRACE_wave_f_nm_np1_fr_goo_37.avi?raw=true&quot;</span><span class="p">,</span>
    <span class="s2">&quot;./dataset/1&quot;</span><span class="p">,</span>
    <span class="s2">&quot;RATRACE_wave_f_nm_np1_fr_goo_37.avi&quot;</span>
<span class="p">)</span>
<span class="n">download_url</span><span class="p">(</span>
    <span class="s2">&quot;https://github.com/pytorch/vision/blob/main/test/assets/videos/SOX5yA1l24A.mp4?raw=true&quot;</span><span class="p">,</span>
    <span class="s2">&quot;./dataset/2&quot;</span><span class="p">,</span>
    <span class="s2">&quot;SOX5yA1l24A.mp4&quot;</span>
<span class="p">)</span>
<span class="n">download_url</span><span class="p">(</span>
    <span class="s2">&quot;https://github.com/pytorch/vision/blob/main/test/assets/videos/v_SoccerJuggling_g23_c01.avi?raw=true&quot;</span><span class="p">,</span>
    <span class="s2">&quot;./dataset/2&quot;</span><span class="p">,</span>
    <span class="s2">&quot;v_SoccerJuggling_g23_c01.avi&quot;</span>
<span class="p">)</span>
<span class="n">download_url</span><span class="p">(</span>
    <span class="s2">&quot;https://github.com/pytorch/vision/blob/main/test/assets/videos/v_SoccerJuggling_g24_c01.avi?raw=true&quot;</span><span class="p">,</span>
    <span class="s2">&quot;./dataset/2&quot;</span><span class="p">,</span>
    <span class="s2">&quot;v_SoccerJuggling_g24_c01.avi&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading https://raw.githubusercontent.com/pytorch/vision/main/test/assets/videos/WUzgd7C1pWA.mp4 to ./dataset/1/WUzgd7C1pWA.mp4

0.1%
0.2%
0.3%
0.5%
0.6%
0.7%
0.8%
0.9%
1.0%
1.2%
1.3%
1.4%
1.5%
1.6%
1.7%
1.8%
2.0%
2.1%
2.2%
2.3%
2.4%
2.5%
2.6%
2.8%
2.9%
3.0%
3.1%
3.2%
3.3%
3.5%
3.6%
3.7%
3.8%
3.9%
4.0%
4.1%
4.3%
4.4%
4.5%
4.6%
4.7%
4.8%
4.9%
5.1%
5.2%
5.3%
5.4%
5.5%
5.6%
5.8%
5.9%
6.0%
6.1%
6.2%
6.3%
6.4%
6.6%
6.7%
6.8%
6.9%
7.0%
7.1%
7.3%
7.4%
7.5%
7.6%
7.7%
7.8%
7.9%
8.1%
8.2%
8.3%
8.4%
8.5%
8.6%
8.7%
8.9%
9.0%
9.1%
9.2%
9.3%
9.4%
9.6%
9.7%
9.8%
9.9%
10.0%
10.1%
10.2%
10.4%
10.5%
10.6%
10.7%
10.8%
10.9%
11.1%
11.2%
11.3%
11.4%
11.5%
11.6%
11.7%
11.9%
12.0%
12.1%
12.2%
12.3%
12.4%
12.5%
12.7%
12.8%
12.9%
13.0%
13.1%
13.2%
13.4%
13.5%
13.6%
13.7%
13.8%
13.9%
14.0%
14.2%
14.3%
14.4%
14.5%
14.6%
14.7%
14.8%
15.0%
15.1%
15.2%
15.3%
15.4%
15.5%
15.7%
15.8%
15.9%
16.0%
16.1%
16.2%
16.3%
16.5%
16.6%
16.7%
16.8%
16.9%
17.0%
17.2%
17.3%
17.4%
17.5%
17.6%
17.7%
17.8%
18.0%
18.1%
18.2%
18.3%
18.4%
18.5%
18.6%
18.8%
18.9%
19.0%
19.1%
19.2%
19.3%
19.5%
19.6%
19.7%
19.8%
19.9%
20.0%
20.1%
20.3%
20.4%
20.5%
20.6%
20.7%
20.8%
20.9%
21.1%
21.2%
21.3%
21.4%
21.5%
21.6%
21.8%
21.9%
22.0%
22.1%
22.2%
22.3%
22.4%
22.6%
22.7%
22.8%
22.9%
23.0%
23.1%
23.3%
23.4%
23.5%
23.6%
23.7%
23.8%
23.9%
24.1%
24.2%
24.3%
24.4%
24.5%
24.6%
24.7%
24.9%
25.0%
25.1%
25.2%
25.3%
25.4%
25.6%
25.7%
25.8%
25.9%
26.0%
26.1%
26.2%
26.4%
26.5%
26.6%
26.7%
26.8%
26.9%
27.0%
27.2%
27.3%
27.4%
27.5%
27.6%
27.7%
27.9%
28.0%
28.1%
28.2%
28.3%
28.4%
28.5%
28.7%
28.8%
28.9%
29.0%
29.1%
29.2%
29.4%
29.5%
29.6%
29.7%
29.8%
29.9%
30.0%
30.2%
30.3%
30.4%
30.5%
30.6%
30.7%
30.8%
31.0%
31.1%
31.2%
31.3%
31.4%
31.5%
31.7%
31.8%
31.9%
32.0%
32.1%
32.2%
32.3%
32.5%
32.6%
32.7%
32.8%
32.9%
33.0%
33.2%
33.3%
33.4%
33.5%
33.6%
33.7%
33.8%
34.0%
34.1%
34.2%
34.3%
34.4%
34.5%
34.6%
34.8%
34.9%
35.0%
35.1%
35.2%
35.3%
35.5%
35.6%
35.7%
35.8%
35.9%
36.0%
36.1%
36.3%
36.4%
36.5%
36.6%
36.7%
36.8%
36.9%
37.1%
37.2%
37.3%
37.4%
37.5%
37.6%
37.8%
37.9%
38.0%
38.1%
38.2%
38.3%
38.4%
38.6%
38.7%
38.8%
38.9%
39.0%
39.1%
39.3%
39.4%
39.5%
39.6%
39.7%
39.8%
39.9%
40.1%
40.2%
40.3%
40.4%
40.5%
40.6%
40.7%
40.9%
41.0%
41.1%
41.2%
41.3%
41.4%
41.6%
41.7%
41.8%
41.9%
42.0%
42.1%
42.2%
42.4%
42.5%
42.6%
42.7%
42.8%
42.9%
43.0%
43.2%
43.3%
43.4%
43.5%
43.6%
43.7%
43.9%
44.0%
44.1%
44.2%
44.3%
44.4%
44.5%
44.7%
44.8%
44.9%
45.0%
45.1%
45.2%
45.4%
45.5%
45.6%
45.7%
45.8%
45.9%
46.0%
46.2%
46.3%
46.4%
46.5%
46.6%
46.7%
46.8%
47.0%
47.1%
47.2%
47.3%
47.4%
47.5%
47.7%
47.8%
47.9%
48.0%
48.1%
48.2%
48.3%
48.5%
48.6%
48.7%
48.8%
48.9%
49.0%
49.2%
49.3%
49.4%
49.5%
49.6%
49.7%
49.8%
50.0%
50.1%
50.2%
50.3%
50.4%
50.5%
50.6%
50.8%
50.9%
51.0%
51.1%
51.2%
51.3%
51.5%
51.6%
51.7%
51.8%
51.9%
52.0%
52.1%
52.3%
52.4%
52.5%
52.6%
52.7%
52.8%
52.9%
53.1%
53.2%
53.3%
53.4%
53.5%
53.6%
53.8%
53.9%
54.0%
54.1%
54.2%
54.3%
54.4%
54.6%
54.7%
54.8%
54.9%
55.0%
55.1%
55.3%
55.4%
55.5%
55.6%
55.7%
55.8%
55.9%
56.1%
56.2%
56.3%
56.4%
56.5%
56.6%
56.7%
56.9%
57.0%
57.1%
57.2%
57.3%
57.4%
57.6%
57.7%
57.8%
57.9%
58.0%
58.1%
58.2%
58.4%
58.5%
58.6%
58.7%
58.8%
58.9%
59.0%
59.2%
59.3%
59.4%
59.5%
59.6%
59.7%
59.9%
60.0%
60.1%
60.2%
60.3%
60.4%
60.5%
60.7%
60.8%
60.9%
61.0%
61.1%
61.2%
61.4%
61.5%
61.6%
61.7%
61.8%
61.9%
62.0%
62.2%
62.3%
62.4%
62.5%
62.6%
62.7%
62.8%
63.0%
63.1%
63.2%
63.3%
63.4%
63.5%
63.7%
63.8%
63.9%
64.0%
64.1%
64.2%
64.3%
64.5%
64.6%
64.7%
64.8%
64.9%
65.0%
65.1%
65.3%
65.4%
65.5%
65.6%
65.7%
65.8%
66.0%
66.1%
66.2%
66.3%
66.4%
66.5%
66.6%
66.8%
66.9%
67.0%
67.1%
67.2%
67.3%
67.5%
67.6%
67.7%
67.8%
67.9%
68.0%
68.1%
68.3%
68.4%
68.5%
68.6%
68.7%
68.8%
68.9%
69.1%
69.2%
69.3%
69.4%
69.5%
69.6%
69.8%
69.9%
70.0%
70.1%
70.2%
70.3%
70.4%
70.6%
70.7%
70.8%
70.9%
71.0%
71.1%
71.3%
71.4%
71.5%
71.6%
71.7%
71.8%
71.9%
72.1%
72.2%
72.3%
72.4%
72.5%
72.6%
72.7%
72.9%
73.0%
73.1%
73.2%
73.3%
73.4%
73.6%
73.7%
73.8%
73.9%
74.0%
74.1%
74.2%
74.4%
74.5%
74.6%
74.7%
74.8%
74.9%
75.0%
75.2%
75.3%
75.4%
75.5%
75.6%
75.7%
75.9%
76.0%
76.1%
76.2%
76.3%
76.4%
76.5%
76.7%
76.8%
76.9%
77.0%
77.1%
77.2%
77.4%
77.5%
77.6%
77.7%
77.8%
77.9%
78.0%
78.2%
78.3%
78.4%
78.5%
78.6%
78.7%
78.8%
79.0%
79.1%
79.2%
79.3%
79.4%
79.5%
79.7%
79.8%
79.9%
80.0%
80.1%
80.2%
80.3%
80.5%
80.6%
80.7%
80.8%
80.9%
81.0%
81.1%
81.3%
81.4%
81.5%
81.6%
81.7%
81.8%
82.0%
82.1%
82.2%
82.3%
82.4%
82.5%
82.6%
82.8%
82.9%
83.0%
83.1%
83.2%
83.3%
83.5%
83.6%
83.7%
83.8%
83.9%
84.0%
84.1%
84.3%
84.4%
84.5%
84.6%
84.7%
84.8%
84.9%
85.1%
85.2%
85.3%
85.4%
85.5%
85.6%
85.8%
85.9%
86.0%
86.1%
86.2%
86.3%
86.4%
86.6%
86.7%
86.8%
86.9%
87.0%
87.1%
87.2%
87.4%
87.5%
87.6%
87.7%
87.8%
87.9%
88.1%
88.2%
88.3%
88.4%
88.5%
88.6%
88.7%
88.9%
89.0%
89.1%
89.2%
89.3%
89.4%
89.6%
89.7%
89.8%
89.9%
90.0%
90.1%
90.2%
90.4%
90.5%
90.6%
90.7%
90.8%
90.9%
91.0%
91.2%
91.3%
91.4%
91.5%
91.6%
91.7%
91.9%
92.0%
92.1%
92.2%
92.3%
92.4%
92.5%
92.7%
92.8%
92.9%
93.0%
93.1%
93.2%
93.4%
93.5%
93.6%
93.7%
93.8%
93.9%
94.0%
94.2%
94.3%
94.4%
94.5%
94.6%
94.7%
94.8%
95.0%
95.1%
95.2%
95.3%
95.4%
95.5%
95.7%
95.8%
95.9%
96.0%
96.1%
96.2%
96.3%
96.5%
96.6%
96.7%
96.8%
96.9%
97.0%
97.1%
97.3%
97.4%
97.5%
97.6%
97.7%
97.8%
98.0%
98.1%
98.2%
98.3%
98.4%
98.5%
98.6%
98.8%
98.9%
99.0%
99.1%
99.2%
99.3%
99.5%
99.6%
99.7%
99.8%
99.9%
100.0%
Downloading https://raw.githubusercontent.com/pytorch/vision/main/test/assets/videos/RATRACE_wave_f_nm_np1_fr_goo_37.avi to ./dataset/1/RATRACE_wave_f_nm_np1_fr_goo_37.avi

0.4%
0.8%
1.2%
1.6%
1.9%
2.3%
2.7%
3.1%
3.5%
3.9%
4.3%
4.7%
5.0%
5.4%
5.8%
6.2%
6.6%
7.0%
7.4%
7.8%
8.2%
8.5%
8.9%
9.3%
9.7%
10.1%
10.5%
10.9%
11.3%
11.7%
12.0%
12.4%
12.8%
13.2%
13.6%
14.0%
14.4%
14.8%
15.1%
15.5%
15.9%
16.3%
16.7%
17.1%
17.5%
17.9%
18.3%
18.6%
19.0%
19.4%
19.8%
20.2%
20.6%
21.0%
21.4%
21.7%
22.1%
22.5%
22.9%
23.3%
23.7%
24.1%
24.5%
24.9%
25.2%
25.6%
26.0%
26.4%
26.8%
27.2%
27.6%
28.0%
28.3%
28.7%
29.1%
29.5%
29.9%
30.3%
30.7%
31.1%
31.5%
31.8%
32.2%
32.6%
33.0%
33.4%
33.8%
34.2%
34.6%
35.0%
35.3%
35.7%
36.1%
36.5%
36.9%
37.3%
37.7%
38.1%
38.4%
38.8%
39.2%
39.6%
40.0%
40.4%
40.8%
41.2%
41.6%
41.9%
42.3%
42.7%
43.1%
43.5%
43.9%
44.3%
44.7%
45.0%
45.4%
45.8%
46.2%
46.6%
47.0%
47.4%
47.8%
48.2%
48.5%
48.9%
49.3%
49.7%
50.1%
50.5%
50.9%
51.3%
51.7%
52.0%
52.4%
52.8%
53.2%
53.6%
54.0%
54.4%
54.8%
55.1%
55.5%
55.9%
56.3%
56.7%
57.1%
57.5%
57.9%
58.3%
58.6%
59.0%
59.4%
59.8%
60.2%
60.6%
61.0%
61.4%
61.7%
62.1%
62.5%
62.9%
63.3%
63.7%
64.1%
64.5%
64.9%
65.2%
65.6%
66.0%
66.4%
66.8%
67.2%
67.6%
68.0%
68.3%
68.7%
69.1%
69.5%
69.9%
70.3%
70.7%
71.1%
71.5%
71.8%
72.2%
72.6%
73.0%
73.4%
73.8%
74.2%
74.6%
75.0%
75.3%
75.7%
76.1%
76.5%
76.9%
77.3%
77.7%
78.1%
78.4%
78.8%
79.2%
79.6%
80.0%
80.4%
80.8%
81.2%
81.6%
81.9%
82.3%
82.7%
83.1%
83.5%
83.9%
84.3%
84.7%
85.0%
85.4%
85.8%
86.2%
86.6%
87.0%
87.4%
87.8%
88.2%
88.5%
88.9%
89.3%
89.7%
90.1%
90.5%
90.9%
91.3%
91.7%
92.0%
92.4%
92.8%
93.2%
93.6%
94.0%
94.4%
94.8%
95.1%
95.5%
95.9%
96.3%
96.7%
97.1%
97.5%
97.9%
98.3%
98.6%
99.0%
99.4%
99.8%
100.2%
Downloading https://raw.githubusercontent.com/pytorch/vision/main/test/assets/videos/SOX5yA1l24A.mp4 to ./dataset/2/SOX5yA1l24A.mp4

0.2%
0.4%
0.5%
0.7%
0.9%
1.1%
1.3%
1.5%
1.6%
1.8%
2.0%
2.2%
2.4%
2.6%
2.7%
2.9%
3.1%
3.3%
3.5%
3.7%
3.8%
4.0%
4.2%
4.4%
4.6%
4.8%
4.9%
5.1%
5.3%
5.5%
5.7%
5.8%
6.0%
6.2%
6.4%
6.6%
6.8%
6.9%
7.1%
7.3%
7.5%
7.7%
7.9%
8.0%
8.2%
8.4%
8.6%
8.8%
9.0%
9.1%
9.3%
9.5%
9.7%
9.9%
10.1%
10.2%
10.4%
10.6%
10.8%
11.0%
11.1%
11.3%
11.5%
11.7%
11.9%
12.1%
12.2%
12.4%
12.6%
12.8%
13.0%
13.2%
13.3%
13.5%
13.7%
13.9%
14.1%
14.3%
14.4%
14.6%
14.8%
15.0%
15.2%
15.4%
15.5%
15.7%
15.9%
16.1%
16.3%
16.4%
16.6%
16.8%
17.0%
17.2%
17.4%
17.5%
17.7%
17.9%
18.1%
18.3%
18.5%
18.6%
18.8%
19.0%
19.2%
19.4%
19.6%
19.7%
19.9%
20.1%
20.3%
20.5%
20.7%
20.8%
21.0%
21.2%
21.4%
21.6%
21.7%
21.9%
22.1%
22.3%
22.5%
22.7%
22.8%
23.0%
23.2%
23.4%
23.6%
23.8%
23.9%
24.1%
24.3%
24.5%
24.7%
24.9%
25.0%
25.2%
25.4%
25.6%
25.8%
26.0%
26.1%
26.3%
26.5%
26.7%
26.9%
27.0%
27.2%
27.4%
27.6%
27.8%
28.0%
28.1%
28.3%
28.5%
28.7%
28.9%
29.1%
29.2%
29.4%
29.6%
29.8%
30.0%
30.2%
30.3%
30.5%
30.7%
30.9%
31.1%
31.3%
31.4%
31.6%
31.8%
32.0%
32.2%
32.3%
32.5%
32.7%
32.9%
33.1%
33.3%
33.4%
33.6%
33.8%
34.0%
34.2%
34.4%
34.5%
34.7%
34.9%
35.1%
35.3%
35.5%
35.6%
35.8%
36.0%
36.2%
36.4%
36.6%
36.7%
36.9%
37.1%
37.3%
37.5%
37.6%
37.8%
38.0%
38.2%
38.4%
38.6%
38.7%
38.9%
39.1%
39.3%
39.5%
39.7%
39.8%
40.0%
40.2%
40.4%
40.6%
40.8%
40.9%
41.1%
41.3%
41.5%
41.7%
41.9%
42.0%
42.2%
42.4%
42.6%
42.8%
42.9%
43.1%
43.3%
43.5%
43.7%
43.9%
44.0%
44.2%
44.4%
44.6%
44.8%
45.0%
45.1%
45.3%
45.5%
45.7%
45.9%
46.1%
46.2%
46.4%
46.6%
46.8%
47.0%
47.2%
47.3%
47.5%
47.7%
47.9%
48.1%
48.2%
48.4%
48.6%
48.8%
49.0%
49.2%
49.3%
49.5%
49.7%
49.9%
50.1%
50.3%
50.4%
50.6%
50.8%
51.0%
51.2%
51.4%
51.5%
51.7%
51.9%
52.1%
52.3%
52.5%
52.6%
52.8%
53.0%
53.2%
53.4%
53.5%
53.7%
53.9%
54.1%
54.3%
54.5%
54.6%
54.8%
55.0%
55.2%
55.4%
55.6%
55.7%
55.9%
56.1%
56.3%
56.5%
56.7%
56.8%
57.0%
57.2%
57.4%
57.6%
57.8%
57.9%
58.1%
58.3%
58.5%
58.7%
58.8%
59.0%
59.2%
59.4%
59.6%
59.8%
59.9%
60.1%
60.3%
60.5%
60.7%
60.9%
61.0%
61.2%
61.4%
61.6%
61.8%
62.0%
62.1%
62.3%
62.5%
62.7%
62.9%
63.1%
63.2%
63.4%
63.6%
63.8%
64.0%
64.1%
64.3%
64.5%
64.7%
64.9%
65.1%
65.2%
65.4%
65.6%
65.8%
66.0%
66.2%
66.3%
66.5%
66.7%
66.9%
67.1%
67.3%
67.4%
67.6%
67.8%
68.0%
68.2%
68.4%
68.5%
68.7%
68.9%
69.1%
69.3%
69.4%
69.6%
69.8%
70.0%
70.2%
70.4%
70.5%
70.7%
70.9%
71.1%
71.3%
71.5%
71.6%
71.8%
72.0%
72.2%
72.4%
72.6%
72.7%
72.9%
73.1%
73.3%
73.5%
73.7%
73.8%
74.0%
74.2%
74.4%
74.6%
74.7%
74.9%
75.1%
75.3%
75.5%
75.7%
75.8%
76.0%
76.2%
76.4%
76.6%
76.8%
76.9%
77.1%
77.3%
77.5%
77.7%
77.9%
78.0%
78.2%
78.4%
78.6%
78.8%
79.0%
79.1%
79.3%
79.5%
79.7%
79.9%
80.0%
80.2%
80.4%
80.6%
80.8%
81.0%
81.1%
81.3%
81.5%
81.7%
81.9%
82.1%
82.2%
82.4%
82.6%
82.8%
83.0%
83.2%
83.3%
83.5%
83.7%
83.9%
84.1%
84.3%
84.4%
84.6%
84.8%
85.0%
85.2%
85.3%
85.5%
85.7%
85.9%
86.1%
86.3%
86.4%
86.6%
86.8%
87.0%
87.2%
87.4%
87.5%
87.7%
87.9%
88.1%
88.3%
88.5%
88.6%
88.8%
89.0%
89.2%
89.4%
89.6%
89.7%
89.9%
90.1%
90.3%
90.5%
90.6%
90.8%
91.0%
91.2%
91.4%
91.6%
91.7%
91.9%
92.1%
92.3%
92.5%
92.7%
92.8%
93.0%
93.2%
93.4%
93.6%
93.8%
93.9%
94.1%
94.3%
94.5%
94.7%
94.9%
95.0%
95.2%
95.4%
95.6%
95.8%
95.9%
96.1%
96.3%
96.5%
96.7%
96.9%
97.0%
97.2%
97.4%
97.6%
97.8%
98.0%
98.1%
98.3%
98.5%
98.7%
98.9%
99.1%
99.2%
99.4%
99.6%
99.8%
100.0%
100.2%
Downloading https://raw.githubusercontent.com/pytorch/vision/main/test/assets/videos/v_SoccerJuggling_g23_c01.avi to ./dataset/2/v_SoccerJuggling_g23_c01.avi

0.2%
0.4%
0.6%
0.8%
1.0%
1.2%
1.4%
1.6%
1.8%
2.0%
2.2%
2.4%
2.6%
2.8%
3.0%
3.2%
3.4%
3.6%
3.8%
4.0%
4.2%
4.4%
4.6%
4.8%
5.0%
5.2%
5.4%
5.6%
5.8%
6.0%
6.2%
6.4%
6.6%
6.8%
7.0%
7.3%
7.5%
7.7%
7.9%
8.1%
8.3%
8.5%
8.7%
8.9%
9.1%
9.3%
9.5%
9.7%
9.9%
10.1%
10.3%
10.5%
10.7%
10.9%
11.1%
11.3%
11.5%
11.7%
11.9%
12.1%
12.3%
12.5%
12.7%
12.9%
13.1%
13.3%
13.5%
13.7%
13.9%
14.1%
14.3%
14.5%
14.7%
14.9%
15.1%
15.3%
15.5%
15.7%
15.9%
16.1%
16.3%
16.5%
16.7%
16.9%
17.1%
17.3%
17.5%
17.7%
17.9%
18.1%
18.3%
18.5%
18.7%
18.9%
19.1%
19.3%
19.5%
19.7%
19.9%
20.1%
20.3%
20.5%
20.7%
20.9%
21.1%
21.4%
21.6%
21.8%
22.0%
22.2%
22.4%
22.6%
22.8%
23.0%
23.2%
23.4%
23.6%
23.8%
24.0%
24.2%
24.4%
24.6%
24.8%
25.0%
25.2%
25.4%
25.6%
25.8%
26.0%
26.2%
26.4%
26.6%
26.8%
27.0%
27.2%
27.4%
27.6%
27.8%
28.0%
28.2%
28.4%
28.6%
28.8%
29.0%
29.2%
29.4%
29.6%
29.8%
30.0%
30.2%
30.4%
30.6%
30.8%
31.0%
31.2%
31.4%
31.6%
31.8%
32.0%
32.2%
32.4%
32.6%
32.8%
33.0%
33.2%
33.4%
33.6%
33.8%
34.0%
34.2%
34.4%
34.6%
34.8%
35.0%
35.2%
35.4%
35.7%
35.9%
36.1%
36.3%
36.5%
36.7%
36.9%
37.1%
37.3%
37.5%
37.7%
37.9%
38.1%
38.3%
38.5%
38.7%
38.9%
39.1%
39.3%
39.5%
39.7%
39.9%
40.1%
40.3%
40.5%
40.7%
40.9%
41.1%
41.3%
41.5%
41.7%
41.9%
42.1%
42.3%
42.5%
42.7%
42.9%
43.1%
43.3%
43.5%
43.7%
43.9%
44.1%
44.3%
44.5%
44.7%
44.9%
45.1%
45.3%
45.5%
45.7%
45.9%
46.1%
46.3%
46.5%
46.7%
46.9%
47.1%
47.3%
47.5%
47.7%
47.9%
48.1%
48.3%
48.5%
48.7%
48.9%
49.1%
49.3%
49.5%
49.8%
50.0%
50.2%
50.4%
50.6%
50.8%
51.0%
51.2%
51.4%
51.6%
51.8%
52.0%
52.2%
52.4%
52.6%
52.8%
53.0%
53.2%
53.4%
53.6%
53.8%
54.0%
54.2%
54.4%
54.6%
54.8%
55.0%
55.2%
55.4%
55.6%
55.8%
56.0%
56.2%
56.4%
56.6%
56.8%
57.0%
57.2%
57.4%
57.6%
57.8%
58.0%
58.2%
58.4%
58.6%
58.8%
59.0%
59.2%
59.4%
59.6%
59.8%
60.0%
60.2%
60.4%
60.6%
60.8%
61.0%
61.2%
61.4%
61.6%
61.8%
62.0%
62.2%
62.4%
62.6%
62.8%
63.0%
63.2%
63.4%
63.6%
63.8%
64.1%
64.3%
64.5%
64.7%
64.9%
65.1%
65.3%
65.5%
65.7%
65.9%
66.1%
66.3%
66.5%
66.7%
66.9%
67.1%
67.3%
67.5%
67.7%
67.9%
68.1%
68.3%
68.5%
68.7%
68.9%
69.1%
69.3%
69.5%
69.7%
69.9%
70.1%
70.3%
70.5%
70.7%
70.9%
71.1%
71.3%
71.5%
71.7%
71.9%
72.1%
72.3%
72.5%
72.7%
72.9%
73.1%
73.3%
73.5%
73.7%
73.9%
74.1%
74.3%
74.5%
74.7%
74.9%
75.1%
75.3%
75.5%
75.7%
75.9%
76.1%
76.3%
76.5%
76.7%
76.9%
77.1%
77.3%
77.5%
77.7%
77.9%
78.2%
78.4%
78.6%
78.8%
79.0%
79.2%
79.4%
79.6%
79.8%
80.0%
80.2%
80.4%
80.6%
80.8%
81.0%
81.2%
81.4%
81.6%
81.8%
82.0%
82.2%
82.4%
82.6%
82.8%
83.0%
83.2%
83.4%
83.6%
83.8%
84.0%
84.2%
84.4%
84.6%
84.8%
85.0%
85.2%
85.4%
85.6%
85.8%
86.0%
86.2%
86.4%
86.6%
86.8%
87.0%
87.2%
87.4%
87.6%
87.8%
88.0%
88.2%
88.4%
88.6%
88.8%
89.0%
89.2%
89.4%
89.6%
89.8%
90.0%
90.2%
90.4%
90.6%
90.8%
91.0%
91.2%
91.4%
91.6%
91.8%
92.0%
92.2%
92.5%
92.7%
92.9%
93.1%
93.3%
93.5%
93.7%
93.9%
94.1%
94.3%
94.5%
94.7%
94.9%
95.1%
95.3%
95.5%
95.7%
95.9%
96.1%
96.3%
96.5%
96.7%
96.9%
97.1%
97.3%
97.5%
97.7%
97.9%
98.1%
98.3%
98.5%
98.7%
98.9%
99.1%
99.3%
99.5%
99.7%
99.9%
100.1%
Downloading https://raw.githubusercontent.com/pytorch/vision/main/test/assets/videos/v_SoccerJuggling_g24_c01.avi to ./dataset/2/v_SoccerJuggling_g24_c01.avi

0.2%
0.3%
0.5%
0.7%
0.8%
1.0%
1.2%
1.3%
1.5%
1.6%
1.8%
2.0%
2.1%
2.3%
2.5%
2.6%
2.8%
3.0%
3.1%
3.3%
3.5%
3.6%
3.8%
3.9%
4.1%
4.3%
4.4%
4.6%
4.8%
4.9%
5.1%
5.3%
5.4%
5.6%
5.8%
5.9%
6.1%
6.2%
6.4%
6.6%
6.7%
6.9%
7.1%
7.2%
7.4%
7.6%
7.7%
7.9%
8.1%
8.2%
8.4%
8.5%
8.7%
8.9%
9.0%
9.2%
9.4%
9.5%
9.7%
9.9%
10.0%
10.2%
10.4%
10.5%
10.7%
10.8%
11.0%
11.2%
11.3%
11.5%
11.7%
11.8%
12.0%
12.2%
12.3%
12.5%
12.7%
12.8%
13.0%
13.2%
13.3%
13.5%
13.6%
13.8%
14.0%
14.1%
14.3%
14.5%
14.6%
14.8%
15.0%
15.1%
15.3%
15.5%
15.6%
15.8%
15.9%
16.1%
16.3%
16.4%
16.6%
16.8%
16.9%
17.1%
17.3%
17.4%
17.6%
17.8%
17.9%
18.1%
18.2%
18.4%
18.6%
18.7%
18.9%
19.1%
19.2%
19.4%
19.6%
19.7%
19.9%
20.1%
20.2%
20.4%
20.5%
20.7%
20.9%
21.0%
21.2%
21.4%
21.5%
21.7%
21.9%
22.0%
22.2%
22.4%
22.5%
22.7%
22.9%
23.0%
23.2%
23.3%
23.5%
23.7%
23.8%
24.0%
24.2%
24.3%
24.5%
24.7%
24.8%
25.0%
25.2%
25.3%
25.5%
25.6%
25.8%
26.0%
26.1%
26.3%
26.5%
26.6%
26.8%
27.0%
27.1%
27.3%
27.5%
27.6%
27.8%
27.9%
28.1%
28.3%
28.4%
28.6%
28.8%
28.9%
29.1%
29.3%
29.4%
29.6%
29.8%
29.9%
30.1%
30.2%
30.4%
30.6%
30.7%
30.9%
31.1%
31.2%
31.4%
31.6%
31.7%
31.9%
32.1%
32.2%
32.4%
32.5%
32.7%
32.9%
33.0%
33.2%
33.4%
33.5%
33.7%
33.9%
34.0%
34.2%
34.4%
34.5%
34.7%
34.9%
35.0%
35.2%
35.3%
35.5%
35.7%
35.8%
36.0%
36.2%
36.3%
36.5%
36.7%
36.8%
37.0%
37.2%
37.3%
37.5%
37.6%
37.8%
38.0%
38.1%
38.3%
38.5%
38.6%
38.8%
39.0%
39.1%
39.3%
39.5%
39.6%
39.8%
39.9%
40.1%
40.3%
40.4%
40.6%
40.8%
40.9%
41.1%
41.3%
41.4%
41.6%
41.8%
41.9%
42.1%
42.2%
42.4%
42.6%
42.7%
42.9%
43.1%
43.2%
43.4%
43.6%
43.7%
43.9%
44.1%
44.2%
44.4%
44.5%
44.7%
44.9%
45.0%
45.2%
45.4%
45.5%
45.7%
45.9%
46.0%
46.2%
46.4%
46.5%
46.7%
46.9%
47.0%
47.2%
47.3%
47.5%
47.7%
47.8%
48.0%
48.2%
48.3%
48.5%
48.7%
48.8%
49.0%
49.2%
49.3%
49.5%
49.6%
49.8%
50.0%
50.1%
50.3%
50.5%
50.6%
50.8%
51.0%
51.1%
51.3%
51.5%
51.6%
51.8%
51.9%
52.1%
52.3%
52.4%
52.6%
52.8%
52.9%
53.1%
53.3%
53.4%
53.6%
53.8%
53.9%
54.1%
54.2%
54.4%
54.6%
54.7%
54.9%
55.1%
55.2%
55.4%
55.6%
55.7%
55.9%
56.1%
56.2%
56.4%
56.6%
56.7%
56.9%
57.0%
57.2%
57.4%
57.5%
57.7%
57.9%
58.0%
58.2%
58.4%
58.5%
58.7%
58.9%
59.0%
59.2%
59.3%
59.5%
59.7%
59.8%
60.0%
60.2%
60.3%
60.5%
60.7%
60.8%
61.0%
61.2%
61.3%
61.5%
61.6%
61.8%
62.0%
62.1%
62.3%
62.5%
62.6%
62.8%
63.0%
63.1%
63.3%
63.5%
63.6%
63.8%
63.9%
64.1%
64.3%
64.4%
64.6%
64.8%
64.9%
65.1%
65.3%
65.4%
65.6%
65.8%
65.9%
66.1%
66.2%
66.4%
66.6%
66.7%
66.9%
67.1%
67.2%
67.4%
67.6%
67.7%
67.9%
68.1%
68.2%
68.4%
68.6%
68.7%
68.9%
69.0%
69.2%
69.4%
69.5%
69.7%
69.9%
70.0%
70.2%
70.4%
70.5%
70.7%
70.9%
71.0%
71.2%
71.3%
71.5%
71.7%
71.8%
72.0%
72.2%
72.3%
72.5%
72.7%
72.8%
73.0%
73.2%
73.3%
73.5%
73.6%
73.8%
74.0%
74.1%
74.3%
74.5%
74.6%
74.8%
75.0%
75.1%
75.3%
75.5%
75.6%
75.8%
75.9%
76.1%
76.3%
76.4%
76.6%
76.8%
76.9%
77.1%
77.3%
77.4%
77.6%
77.8%
77.9%
78.1%
78.3%
78.4%
78.6%
78.7%
78.9%
79.1%
79.2%
79.4%
79.6%
79.7%
79.9%
80.1%
80.2%
80.4%
80.6%
80.7%
80.9%
81.0%
81.2%
81.4%
81.5%
81.7%
81.9%
82.0%
82.2%
82.4%
82.5%
82.7%
82.9%
83.0%
83.2%
83.3%
83.5%
83.7%
83.8%
84.0%
84.2%
84.3%
84.5%
84.7%
84.8%
85.0%
85.2%
85.3%
85.5%
85.6%
85.8%
86.0%
86.1%
86.3%
86.5%
86.6%
86.8%
87.0%
87.1%
87.3%
87.5%
87.6%
87.8%
87.9%
88.1%
88.3%
88.4%
88.6%
88.8%
88.9%
89.1%
89.3%
89.4%
89.6%
89.8%
89.9%
90.1%
90.3%
90.4%
90.6%
90.7%
90.9%
91.1%
91.2%
91.4%
91.6%
91.7%
91.9%
92.1%
92.2%
92.4%
92.6%
92.7%
92.9%
93.0%
93.2%
93.4%
93.5%
93.7%
93.9%
94.0%
94.2%
94.4%
94.5%
94.7%
94.9%
95.0%
95.2%
95.3%
95.5%
95.7%
95.8%
96.0%
96.2%
96.3%
96.5%
96.7%
96.8%
97.0%
97.2%
97.3%
97.5%
97.6%
97.8%
98.0%
98.1%
98.3%
98.5%
98.6%
98.8%
99.0%
99.1%
99.3%
99.5%
99.6%
99.8%
99.9%
100.1%
</pre></div>
</div>
<p>Housekeeping and utilities</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="kn">from</span> <span class="nn">torchvision.datasets.folder</span> <span class="kn">import</span> <span class="n">make_dataset</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">transforms</span></a> <span class="k">as</span> <span class="n">t</span>


<span class="k">def</span> <span class="nf">_find_classes</span><span class="p">(</span><span class="nb">dir</span><span class="p">):</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <a href="https://docs.python.org/3/library/os.html#os.scandir" title="os.scandir" class="sphx-glr-backref-module-os sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">scandir</span></a><span class="p">(</span><span class="nb">dir</span><span class="p">)</span> <span class="k">if</span> <span class="n">d</span><span class="o">.</span><span class="n">is_dir</span><span class="p">()]</span>
    <span class="n">classes</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
    <span class="n">class_to_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">cls_name</span><span class="p">:</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i</span></a> <span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i</span></a><span class="p">,</span> <span class="n">cls_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">classes</span><span class="p">)}</span>
    <span class="k">return</span> <span class="n">classes</span><span class="p">,</span> <span class="n">class_to_idx</span>


<span class="k">def</span> <span class="nf">get_samples</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">extensions</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;.mp4&quot;</span><span class="p">,</span> <span class="s2">&quot;.avi&quot;</span><span class="p">)):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">class_to_idx</span> <span class="o">=</span> <span class="n">_find_classes</span><span class="p">(</span><span class="n">root</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">make_dataset</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">class_to_idx</span><span class="p">,</span> <span class="n">extensions</span><span class="o">=</span><span class="n">extensions</span><span class="p">)</span>
</pre></div>
</div>
<p>We are going to define the dataset and some basic arguments.
We assume the structure of the FolderDataset, and add the following parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">clip_len</span></code>: length of a clip in frames</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">frame_transform</span></code>: transform for every frame individually</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">video_transform</span></code>: transform on a video sequence</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We actually add epoch size as using <code class="xref py py-func docutils literal notranslate"><span class="pre">IterableDataset()</span></code>
class allows us to naturally oversample clips or images from each video if needed.</p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">RandomDataset</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset" title="torch.utils.data.IterableDataset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">IterableDataset</span></a><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">root</span><span class="p">,</span> <span class="n">epoch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">frame_transform</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">video_transform</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">clip_len</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset" title="torch.utils.data.IterableDataset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">RandomDataset</span></a><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">samples</span> <span class="o">=</span> <span class="n">get_samples</span><span class="p">(</span><span class="n">root</span><span class="p">)</span>

        <span class="c1"># Allow for temporal jittering</span>
        <span class="k">if</span> <span class="n">epoch_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">epoch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">samples</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epoch_size</span> <span class="o">=</span> <span class="n">epoch_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">clip_len</span> <span class="o">=</span> <span class="n">clip_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">frame_transform</span> <span class="o">=</span> <span class="n">frame_transform</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">video_transform</span> <span class="o">=</span> <span class="n">video_transform</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i</span></a> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">epoch_size</span><span class="p">):</span>
            <span class="c1"># Get random sample</span>
            <span class="n">path</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/random.html#random.choice" title="random.choice" class="sphx-glr-backref-module-random sphx-glr-backref-type-py-function"><span class="n">random</span><span class="o">.</span><span class="n">choice</span></a><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">samples</span><span class="p">)</span>
            <span class="c1"># Get video object</span>
            <span class="n">vid</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">VideoReader</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;video&quot;</span><span class="p">)</span>
            <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">metadata</span></a> <span class="o">=</span> <span class="n">vid</span><span class="o">.</span><span class="n">get_metadata</span><span class="p">()</span>
            <span class="n">video_frames</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># video frame buffer</span>

            <span class="c1"># Seek and return frames</span>
            <span class="n">max_seek</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">metadata</span></a><span class="p">[</span><span class="s2">&quot;video&quot;</span><span class="p">][</span><span class="s1">&#39;duration&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">clip_len</span> <span class="o">/</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">metadata</span></a><span class="p">[</span><span class="s2">&quot;video&quot;</span><span class="p">][</span><span class="s1">&#39;fps&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">start</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/random.html#random.uniform" title="random.uniform" class="sphx-glr-backref-module-random sphx-glr-backref-type-py-function"><span class="n">random</span><span class="o">.</span><span class="n">uniform</span></a><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">max_seek</span><span class="p">)</span>
            <span class="k">for</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frame</span></a> <span class="ow">in</span> <a href="https://docs.python.org/3/library/itertools.html#itertools.islice" title="itertools.islice" class="sphx-glr-backref-module-itertools sphx-glr-backref-type-py-function"><span class="n">itertools</span><span class="o">.</span><span class="n">islice</span></a><span class="p">(</span><span class="n">vid</span><span class="o">.</span><span class="n">seek</span><span class="p">(</span><span class="n">start</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_len</span><span class="p">):</span>
                <span class="n">video_frames</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">frame_transform</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frame</span></a><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">]))</span>
                <span class="n">current_pts</span> <span class="o">=</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">frame</span></a><span class="p">[</span><span class="s1">&#39;pts&#39;</span><span class="p">]</span>
            <span class="c1"># Stack it into a tensor</span>
            <span class="n">video</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.stack.html#torch.stack" title="torch.stack" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">stack</span></a><span class="p">(</span><span class="n">video_frames</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">video_transform</span><span class="p">:</span>
                <span class="n">video</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">video_transform</span><span class="p">(</span><span class="n">video</span><span class="p">)</span>
            <span class="n">output</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;path&#39;</span><span class="p">:</span> <span class="n">path</span><span class="p">,</span>
                <span class="s1">&#39;video&#39;</span><span class="p">:</span> <span class="n">video</span><span class="p">,</span>
                <span class="s1">&#39;target&#39;</span><span class="p">:</span> <span class="n">target</span><span class="p">,</span>
                <span class="s1">&#39;start&#39;</span><span class="p">:</span> <span class="n">start</span><span class="p">,</span>
                <span class="s1">&#39;end&#39;</span><span class="p">:</span> <span class="n">current_pts</span><span class="p">}</span>
            <span class="k">yield</span> <span class="n">output</span>
</pre></div>
</div>
<p>Given a path of videos in a folder structure, i.e:</p>
<ul class="simple">
<li><dl class="simple">
<dt>dataset</dt><dd><ul>
<li><dl class="simple">
<dt>class 1</dt><dd><ul>
<li><p>file 0</p></li>
<li><p>file 1</p></li>
<li><p>…</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>class 2</dt><dd><ul>
<li><p>file 0</p></li>
<li><p>file 1</p></li>
<li><p>…</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>…</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<p>We can generate a dataloader and test the dataset.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">transforms</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class"><span class="n">t</span><span class="o">.</span><span class="n">Resize</span></a><span class="p">((</span><span class="mi">112</span><span class="p">,</span> <span class="mi">112</span><span class="p">))]</span>
<span class="n">frame_transform</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">transforms</span></a><span class="p">)</span>

<span class="n">dataset</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset" title="torch.utils.data.IterableDataset" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">RandomDataset</span></a><span class="p">(</span><span class="s2">&quot;./dataset&quot;</span><span class="p">,</span> <span class="n">epoch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">frame_transform</span><span class="o">=</span><span class="n">frame_transform</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">DataLoader</span></a>
<a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">loader</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class"><span class="n">DataLoader</span></a><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;video&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;start&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;end&#39;</span><span class="p">:</span> <span class="p">[],</span> <span class="s1">&#39;tensorsize&#39;</span><span class="p">:</span> <span class="p">[]}</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch</span></a> <span class="ow">in</span> <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader" title="torch.utils.data.DataLoader" class="sphx-glr-backref-module-torch-utils-data sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">loader</span></a><span class="p">:</span>
    <span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i</span></a> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch</span></a><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">])):</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="p">[</span><span class="s1">&#39;video&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch</span></a><span class="p">[</span><span class="s1">&#39;path&#39;</span><span class="p">][</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i</span></a><span class="p">])</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="p">[</span><span class="s1">&#39;start&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch</span></a><span class="p">[</span><span class="s1">&#39;start&#39;</span><span class="p">][</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i</span></a><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="p">[</span><span class="s1">&#39;end&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch</span></a><span class="p">[</span><span class="s1">&#39;end&#39;</span><span class="p">][</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i</span></a><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="p">[</span><span class="s1">&#39;tensorsize&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch</span></a><span class="p">[</span><span class="s1">&#39;video&#39;</span><span class="p">][</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i</span></a><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">data</span></a><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>{&#39;video&#39;: [&#39;./dataset/2/v_SoccerJuggling_g23_c01.avi&#39;, &#39;./dataset/1/RATRACE_wave_f_nm_np1_fr_goo_37.avi&#39;, &#39;./dataset/2/v_SoccerJuggling_g23_c01.avi&#39;, &#39;./dataset/1/RATRACE_wave_f_nm_np1_fr_goo_37.avi&#39;, &#39;./dataset/1/RATRACE_wave_f_nm_np1_fr_goo_37.avi&#39;], &#39;start&#39;: [1.4957954967768776, 1.1528862625566016, 4.795084146240139, 1.3650015642906173, 0.06481206045123106], &#39;end&#39;: [2.002, 1.666667, 5.3053, 1.8666669999999999, 0.5666669999999999], &#39;tensorsize&#39;: [torch.Size([16, 3, 112, 112]), torch.Size([16, 3, 112, 112]), torch.Size([16, 3, 112, 112]), torch.Size([16, 3, 112, 112]), torch.Size([16, 3, 112, 112])]}
</pre></div>
</div>
</div>
<div class="section" id="data-visualization">
<h2>4. Data Visualization<a class="headerlink" href="#data-visualization" title="Permalink to this headline">¶</a></h2>
<p>Example of visualized video</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="k">for</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i</span></a> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">16</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i</span></a> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#dict" title="builtins.dict" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">batch</span></a><span class="p">[</span><span class="s2">&quot;video&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">i</span></a><span class="p">,</span> <span class="o">...</span><span class="p">]</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_video_api_001.png" srcset="../_images/sphx_glr_plot_video_api_001.png" alt="plot video api" class = "sphx-glr-single-img"/><p>Cleanup the video and dataset:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<a href="https://docs.python.org/3/library/os.html#os.remove" title="os.remove" class="sphx-glr-backref-module-os sphx-glr-backref-type-py-function"><span class="n">os</span><span class="o">.</span><span class="n">remove</span></a><span class="p">(</span><span class="s2">&quot;./WUzgd7C1pWA.mp4&quot;</span><span class="p">)</span>
<a href="https://docs.python.org/3/library/shutil.html#shutil.rmtree" title="shutil.rmtree" class="sphx-glr-backref-module-shutil sphx-glr-backref-type-py-function"><span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span></a><span class="p">(</span><span class="s2">&quot;./dataset&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.471 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-plot-video-api-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/19a6d5f6ec4c29d7cbcc4a07a4b5339c/plot_video_api.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_video_api.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/0a0ea3da81f0782f42d1ded74c1acb75/plot_video_api.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_video_api.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="plot_visualization_utils.html" class="btn btn-neutral" title="Visualization utilities" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017-present, Torch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Video API</a><ul>
<li><a class="reference internal" href="#introduction-building-a-new-video-object-and-examining-the-properties">1. Introduction: building a new video object and examining the properties</a></li>
<li><a class="reference internal" href="#building-a-sample-read-video-function">2. Building a sample read_video function</a></li>
<li><a class="reference internal" href="#building-an-example-randomly-sampled-dataset-can-be-applied-to-training-dataest-of-kinetics400">3. Building an example randomly sampled dataset (can be applied to training dataest of kinetics400)</a></li>
<li><a class="reference internal" href="#data-visualization">4. Data Visualization</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/clipboard.min.js"></script>
         <script src="../_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
            <a href="https://www.youtube.com/pytorch" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/elastic/">TorchElastic</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>